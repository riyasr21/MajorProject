{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdWgjX6C4e1Y",
        "outputId": "c9c9967a-a935-4d77-b350-25399286d4e6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LwBbSGpcKe1L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import PIL\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop\n",
        "from PIL import Image\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import Model, layers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13EjMCZ2KyGm",
        "outputId": "18303470-ef95-4cf9-e7be-458d288c82a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "data = pd.read_csv('/content/drive/MyDrive/training_details_zoomed.csv')\n",
        "\n",
        "\n",
        "data\n"
      ],
      "metadata": {
        "id": "nxzul11LlmmJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "810cd99c-05bc-45f4-aaf7-bd558c0d5922"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   path  label      crop\n",
              "0     /content/drive/MyDrive/cotton_zoomed/aug-DJI_0...      1    cotton\n",
              "1     /content/drive/MyDrive/cotton_zoomed/aug-DJI_0...      1    cotton\n",
              "2     /content/drive/MyDrive/cotton_zoomed/aug-DJI_0...      1    cotton\n",
              "3     /content/drive/MyDrive/cotton_zoomed/aug-DJI_0...      1    cotton\n",
              "4     /content/drive/MyDrive/cotton_zoomed/aug-DJI_0...      1    cotton\n",
              "...                                                 ...    ...       ...\n",
              "1495  /content/drive/MyDrive/redGram_zoomed/aug4-DJI...      0  red gram\n",
              "1496  /content/drive/MyDrive/redGram_zoomed/aug4-DJI...      0  red gram\n",
              "1497  /content/drive/MyDrive/redGram_zoomed/aug4-DJI...      0  red gram\n",
              "1498  /content/drive/MyDrive/redGram_zoomed/aug4-DJI...      0  red gram\n",
              "1499  /content/drive/MyDrive/redGram_zoomed/aug4-DJI...      0  red gram\n",
              "\n",
              "[1500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30c3a917-b227-48b6-8666-9eb0f1b5e708\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>crop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/cotton_zoomed/aug-DJI_0...</td>\n",
              "      <td>1</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/cotton_zoomed/aug-DJI_0...</td>\n",
              "      <td>1</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/cotton_zoomed/aug-DJI_0...</td>\n",
              "      <td>1</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/cotton_zoomed/aug-DJI_0...</td>\n",
              "      <td>1</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/cotton_zoomed/aug-DJI_0...</td>\n",
              "      <td>1</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug4-DJI...</td>\n",
              "      <td>0</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug4-DJI...</td>\n",
              "      <td>0</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug4-DJI...</td>\n",
              "      <td>0</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug4-DJI...</td>\n",
              "      <td>0</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug4-DJI...</td>\n",
              "      <td>0</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30c3a917-b227-48b6-8666-9eb0f1b5e708')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30c3a917-b227-48b6-8666-9eb0f1b5e708 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30c3a917-b227-48b6-8666-9eb0f1b5e708');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29e57650-51d2-4f32-91b1-1ae69f84ba14\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29e57650-51d2-4f32-91b1-1ae69f84ba14')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29e57650-51d2-4f32-91b1-1ae69f84ba14 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the features (X) and the target variable (y)\n",
        "X = data.drop(columns=['label'])  # Adjust 'target_column_name' to the name of your target variable\n",
        "y = data['label']  # Adjust 'target_column_name' to the name of your target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "6pHhBiTs5m6S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-zSrLi2VLSWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "66d89243-4ffc-47bb-9d3b-c284bb1fa82c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   path      crop\n",
              "382   /content/drive/MyDrive/cotton_zoomed/DJI_0643.JPG    cotton\n",
              "538    /content/drive/MyDrive/maize_zoomed/DJI_0118.JPG     maize\n",
              "1493  /content/drive/MyDrive/redGram_zoomed/aug4-DJI...  red gram\n",
              "1112  /content/drive/MyDrive/redGram_zoomed/DJI_0237...  red gram\n",
              "324   /content/drive/MyDrive/cotton_zoomed/DJI_0587.JPG    cotton\n",
              "...                                                 ...       ...\n",
              "1130  /content/drive/MyDrive/redGram_zoomed/aug-DJI_...  red gram\n",
              "1294  /content/drive/MyDrive/redGram_zoomed/aug2-DJI...  red gram\n",
              "860    /content/drive/MyDrive/maize_zoomed/DJI_0807.JPG     maize\n",
              "1459  /content/drive/MyDrive/redGram_zoomed/aug4-DJI...  red gram\n",
              "1126  /content/drive/MyDrive/redGram_zoomed/aug-DJI_...  red gram\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29fec851-f9fd-4bd4-8016-c4b5ce1b0cd9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>crop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>/content/drive/MyDrive/cotton_zoomed/DJI_0643.JPG</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>/content/drive/MyDrive/maize_zoomed/DJI_0118.JPG</td>\n",
              "      <td>maize</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug4-DJI...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1112</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/DJI_0237...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>/content/drive/MyDrive/cotton_zoomed/DJI_0587.JPG</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug-DJI_...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug2-DJI...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>/content/drive/MyDrive/maize_zoomed/DJI_0807.JPG</td>\n",
              "      <td>maize</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug4-DJI...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug-DJI_...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29fec851-f9fd-4bd4-8016-c4b5ce1b0cd9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29fec851-f9fd-4bd4-8016-c4b5ce1b0cd9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29fec851-f9fd-4bd4-8016-c4b5ce1b0cd9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a26cd3f2-e629-4612-bf77-977cb5f6b693\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a26cd3f2-e629-4612-bf77-977cb5f6b693')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a26cd3f2-e629-4612-bf77-977cb5f6b693 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "uwnpB-tcquzP",
        "outputId": "f60469db-cf21-41be-9d2a-13e8ceff9cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   path      crop\n",
              "1116  /content/drive/MyDrive/redGram_zoomed/DJI_0217...  red gram\n",
              "1368  /content/drive/MyDrive/redGram_zoomed/aug3-DJI...  red gram\n",
              "422   /content/drive/MyDrive/cotton_zoomed/DJI_0690.JPG    cotton\n",
              "413   /content/drive/MyDrive/cotton_zoomed/DJI_0684.JPG    cotton\n",
              "451   /content/drive/MyDrive/cotton_zoomed/DJI_0716.JPG    cotton\n",
              "...                                                 ...       ...\n",
              "983   /content/drive/MyDrive/maize_zoomed/aug-DJI_09...     maize\n",
              "799    /content/drive/MyDrive/maize_zoomed/DJI_0855.JPG     maize\n",
              "1265  /content/drive/MyDrive/redGram_zoomed/aug2-DJI...  red gram\n",
              "1150  /content/drive/MyDrive/redGram_zoomed/aug-DJI_...  red gram\n",
              "824    /content/drive/MyDrive/maize_zoomed/DJI_0773.JPG     maize\n",
              "\n",
              "[300 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1300761-978b-4c74-8fb3-b9cfc7c757b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>crop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1116</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/DJI_0217...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1368</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug3-DJI...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>/content/drive/MyDrive/cotton_zoomed/DJI_0690.JPG</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>/content/drive/MyDrive/cotton_zoomed/DJI_0684.JPG</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>/content/drive/MyDrive/cotton_zoomed/DJI_0716.JPG</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>/content/drive/MyDrive/maize_zoomed/aug-DJI_09...</td>\n",
              "      <td>maize</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>/content/drive/MyDrive/maize_zoomed/DJI_0855.JPG</td>\n",
              "      <td>maize</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug2-DJI...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1150</th>\n",
              "      <td>/content/drive/MyDrive/redGram_zoomed/aug-DJI_...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>/content/drive/MyDrive/maize_zoomed/DJI_0773.JPG</td>\n",
              "      <td>maize</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1300761-978b-4c74-8fb3-b9cfc7c757b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1300761-978b-4c74-8fb3-b9cfc7c757b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1300761-978b-4c74-8fb3-b9cfc7c757b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-722c677b-f45b-4273-b0ed-499e5b240bc9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-722c677b-f45b-4273-b0ed-499e5b240bc9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-722c677b-f45b-4273-b0ed-499e5b240bc9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FtW12_NvLuSN"
      },
      "outputs": [],
      "source": [
        "def path_to_RGB(path :str):\n",
        "   path=path.replace('/input','/input/agriculture-crop-images/crop_images')\n",
        "   img = Image.open(path)\n",
        "   img = img.resize((28, 28))\n",
        "   img_arr = np.array(img)\n",
        "   img_arr = img_arr.reshape(28,28,3)\n",
        "   return img_arr\n",
        "\n",
        "def path_to_RGB_test(path :str):\n",
        "   img = Image.open(path)\n",
        "   img = img.resize((28, 28))\n",
        "   img_arr = np.array(img)\n",
        "   img_arr = img_arr.reshape(28,28,3)\n",
        "   return img_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VERqlApOMXHL"
      },
      "outputs": [],
      "source": [
        "X_train['path']=X_train['path'].apply(path_to_RGB)\n",
        "X_test['path']=X_test['path'].apply(path_to_RGB_test)\n",
        "X_train['path']=X_train['path']/255\n",
        "X_test['path']=X_test['path']/255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UqrezZtFpor",
        "outputId": "38a8ef9e-655f-49bc-a553-797ed8f85288"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = '/content/drive/MyDrive/x_train_zoomed.csv'\n",
        "X_train.to_csv(csv_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "IMcqWF50F1zP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fcsseKonUHyx"
      },
      "outputs": [],
      "source": [
        "no_of_training= X_train['path'].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OKNvZ_VEUKRh"
      },
      "outputs": [],
      "source": [
        "X=[]\n",
        "for x in X_train['path']:\n",
        "    for j in x:\n",
        "        for i in j:\n",
        "            for a in i :\n",
        "                X.append(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ew9uvw9KUNn2"
      },
      "outputs": [],
      "source": [
        "X=np.asarray(X).reshape(no_of_training,28,28,3)\n",
        "Y=y_train\n",
        "Y=to_categorical(Y,num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RC3T0rF_UN-1"
      },
      "outputs": [],
      "source": [
        "# model = Sequential()\n",
        "\n",
        "# model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',\n",
        "#                  activation ='relu', input_shape = (28,28,3)))\n",
        "# model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',\n",
        "#                  activation ='relu'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',\n",
        "#                  activation ='relu'))\n",
        "# model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',\n",
        "#                  activation ='relu'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256, activation = \"relu\"))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(5, activation = \"softmax\"))\n",
        "\n",
        "#modified ver 1\n",
        "# from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "# from keras.models import Model\n",
        "\n",
        "# # Define input layer\n",
        "# input_layer = Input(shape=(28, 28, 3))\n",
        "\n",
        "# # First convolutional layer\n",
        "# conv1 = Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu')(input_layer)\n",
        "\n",
        "# # Second convolutional layer\n",
        "# conv2 = Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu')(conv1)\n",
        "\n",
        "# # Max-pooling layer\n",
        "# pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "# # Dropout layer\n",
        "# dropout1 = Dropout(0.25)(pool1)\n",
        "\n",
        "# # Third convolutional layer\n",
        "# conv3 = Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu')(dropout1)\n",
        "\n",
        "# # Fourth convolutional layer\n",
        "# conv4 = Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu')(conv3)\n",
        "\n",
        "# # Max-pooling layer\n",
        "# pool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv4)\n",
        "\n",
        "# # Dropout layer\n",
        "# dropout2 = Dropout(0.25)(pool2)\n",
        "\n",
        "# # Flatten layer\n",
        "# flatten = Flatten()(dropout2)\n",
        "\n",
        "# # First fully connected layer\n",
        "# fc1 = Dense(256, activation='relu')(flatten)\n",
        "\n",
        "# # Dropout layer\n",
        "# dropout3 = Dropout(0.5)(fc1)\n",
        "\n",
        "# # Second fully connected layer\n",
        "# output_layer = Dense(5, activation='softmax')(dropout3)\n",
        "\n",
        "# # Create the model\n",
        "# model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "#2\n",
        "# from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate\n",
        "# from keras.models import Model\n",
        "\n",
        "# # Define input layer\n",
        "# input_layer = Input(shape=(28, 28, 3))\n",
        "\n",
        "# # First convolutional layer\n",
        "# conv1_1 = Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu')(input_layer)\n",
        "# conv1_2 = Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu')(conv1_1)\n",
        "\n",
        "# # Second convolutional layer\n",
        "# conv2_1 = Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu')(input_layer)\n",
        "# conv2_2 = Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu')(conv2_1)\n",
        "\n",
        "# # Max-pooling layer\n",
        "# pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_2)\n",
        "# pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_2)\n",
        "\n",
        "# # Dropout layer\n",
        "# dropout1 = Dropout(0.25)(pool1)\n",
        "# dropout2 = Dropout(0.25)(pool2)\n",
        "\n",
        "# # Third convolutional layer\n",
        "# conv3 = Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu')(dropout1)\n",
        "\n",
        "# # Fourth convolutional layer\n",
        "# conv4 = Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu')(dropout2)\n",
        "\n",
        "# # Max-pooling layer\n",
        "# pool3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv3)\n",
        "# pool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv4)\n",
        "\n",
        "# # Dropout layer\n",
        "# dropout3 = Dropout(0.25)(pool3)\n",
        "# dropout4 = Dropout(0.25)(pool4)\n",
        "\n",
        "# # Concatenate feature maps from preceding layers\n",
        "# concatenated_features = concatenate([dropout3, dropout4])\n",
        "\n",
        "# # Flatten layer\n",
        "# flatten = Flatten()(concatenated_features)\n",
        "\n",
        "# # First fully connected layer\n",
        "# fc1 = Dense(256, activation='relu')(flatten)\n",
        "\n",
        "# # Dropout layer\n",
        "# dropout5 = Dropout(0.5)(fc1)\n",
        "\n",
        "# # Second fully connected layer\n",
        "# output_layer = Dense(5, activation='softmax')(dropout5)\n",
        "\n",
        "# # Create the model\n",
        "# model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "#3\n",
        "# from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate\n",
        "# from keras.models import Model\n",
        "\n",
        "# # Define input layer\n",
        "# input_layer = Input(shape=(28, 28, 3))\n",
        "\n",
        "# # First convolutional layer\n",
        "# conv1_1 = Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu')(input_layer)\n",
        "# conv1_2 = Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu')(conv1_1)\n",
        "\n",
        "# # Second convolutional layer\n",
        "# conv2_1 = Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu')(input_layer)\n",
        "# conv2_2 = Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu')(conv2_1)\n",
        "\n",
        "# # Max-pooling layer\n",
        "# pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_2)\n",
        "# pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_2)\n",
        "\n",
        "# # Dropout layer\n",
        "# dropout1 = Dropout(0.25)(pool1)\n",
        "# dropout2 = Dropout(0.25)(pool2)\n",
        "\n",
        "# # Third convolutional layer\n",
        "# conv3 = Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu')(dropout1)\n",
        "\n",
        "# # Fourth convolutional layer\n",
        "# conv4 = Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu')(dropout2)\n",
        "\n",
        "# # Max-pooling layer\n",
        "# pool3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv3)\n",
        "# pool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv4)\n",
        "\n",
        "# # Dropout layer\n",
        "# dropout3 = Dropout(0.25)(pool3)\n",
        "# dropout4 = Dropout(0.25)(pool4)\n",
        "\n",
        "# # Concatenate feature maps from preceding layers\n",
        "# concatenated_features = concatenate([dropout3, dropout4])\n",
        "\n",
        "# # Transition block\n",
        "# conv_transition = Conv2D(filters=32, kernel_size=(1, 1), activation='relu')(concatenated_features)\n",
        "# pool_transition = MaxPooling2D(pool_size=(2, 2))(conv_transition)\n",
        "\n",
        "# # Flatten layer\n",
        "# flatten = Flatten()(pool_transition)\n",
        "\n",
        "# # First fully connected layer\n",
        "# fc1 = Dense(256, activation='relu')(flatten)\n",
        "\n",
        "# # Dropout layer\n",
        "# dropout5 = Dropout(0.5)(fc1)\n",
        "\n",
        "# # Second fully connected layer\n",
        "# output_layer = Dense(5, activation='softmax')(dropout5)\n",
        "\n",
        "# # Create the model\n",
        "# model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate, BatchNormalization, Activation\n",
        "from keras.models import Model\n",
        "\n",
        "# Define input layer\n",
        "input_layer = Input(shape=(28, 28, 3))\n",
        "\n",
        "# Function for composite operation (BN + Conv)\n",
        "def composite_function(input_features, filters, kernel_size):\n",
        "    # Batch normalization\n",
        "    x = BatchNormalization()(input_features)\n",
        "    # ReLU activation\n",
        "    x = Activation('relu')(x)\n",
        "    # Convolution\n",
        "    x = Conv2D(filters=filters, kernel_size=kernel_size, padding='Same', activation='relu')(x)\n",
        "    return x\n",
        "\n",
        "# First convolutional layer\n",
        "conv1_1 = composite_function(input_layer, filters=32, kernel_size=(5, 5))\n",
        "conv1_2 = composite_function(conv1_1, filters=32, kernel_size=(5, 5))\n",
        "\n",
        "# Second convolutional layer\n",
        "conv2_1 = composite_function(input_layer, filters=32, kernel_size=(5, 5))\n",
        "conv2_2 = composite_function(conv2_1, filters=32, kernel_size=(5, 5))\n",
        "\n",
        "# Max-pooling layer\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_2)\n",
        "\n",
        "# Dropout layer\n",
        "dropout1 = Dropout(0.25)(pool1)\n",
        "dropout2 = Dropout(0.25)(pool2)\n",
        "\n",
        "# Third convolutional layer\n",
        "conv3 = composite_function(dropout1, filters=64, kernel_size=(3, 3))\n",
        "\n",
        "# Fourth convolutional layer\n",
        "conv4 = composite_function(dropout2, filters=64, kernel_size=(3, 3))\n",
        "\n",
        "# Max-pooling layer\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv3)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv4)\n",
        "\n",
        "# Dropout layer\n",
        "dropout3 = Dropout(0.25)(pool3)\n",
        "dropout4 = Dropout(0.25)(pool4)\n",
        "\n",
        "# Concatenate feature maps from preceding layers\n",
        "concatenated_features = concatenate([dropout3, dropout4])\n",
        "\n",
        "# Transition block\n",
        "conv_transition = composite_function(concatenated_features, filters=32, kernel_size=(1, 1))\n",
        "pool_transition = MaxPooling2D(pool_size=(2, 2))(conv_transition)\n",
        "\n",
        "# Flatten layer\n",
        "flatten = Flatten()(pool_transition)\n",
        "\n",
        "# First fully connected layer\n",
        "fc1 = Dense(256, activation='relu')(flatten)\n",
        "\n",
        "# Dropout layer\n",
        "dropout5 = Dropout(0.5)(fc1)\n",
        "\n",
        "# Second fully connected layer\n",
        "output_layer = Dense(3, activation='softmax')(dropout5)\n",
        "\n",
        "# Create the model\n",
        "model_relu = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08)\n",
        "model_relu.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "iODrUn8s9BD-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rynGuCQZqa8w"
      },
      "outputs": [],
      "source": [
        "#New sl-relu\n",
        "\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense, concatenate, BatchNormalization, Activation, MaxPooling2D\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "# input layer\n",
        "input_layer = Input(shape=(28, 28, 3))\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "def sl_relu(x):\n",
        "    # Define the threshold\n",
        "    threshold = 0.05\n",
        "\n",
        "    # Apply the custom activation function element-wise using TensorFlow operations\n",
        "    condition = tf.math.less(x, 0)\n",
        "    abs_x = tf.abs(x)\n",
        "    log_term = tf.math.log(threshold * x + 1) + tf.abs(tf.math.log(threshold * abs_x + 1) - abs_x)\n",
        "\n",
        "    return tf.where(condition, x / (1 + abs_x), tf.where(tf.math.less_equal(x, 1), x, log_term))\n",
        "\n",
        "\n",
        "\n",
        "# First convolutional layer\n",
        "x1 = Conv2D(32, (3, 3), padding='same')(Conv2D(32, (3, 3), padding='same')(input_layer))\n",
        "x1 = BatchNormalization()(x1)\n",
        "x1 = Activation(sl_relu)(x1)\n",
        "\n",
        "# # SL - ReLU activation function\n",
        "# def sl_relu(x) :\n",
        "#   # Convolutional layer's output\n",
        "#   conv_output = x\n",
        "\n",
        "#   # Convolutional layer's kernel\n",
        "#   conv_layer = x.op.inputs[0]\n",
        "#   kernel = conv_layer.kernel\n",
        "\n",
        "#   if x < 0 :\n",
        "#     return x/ 1 + abs(x)\n",
        "#   else :\n",
        "#     if x <= kernel :\n",
        "#       return x\n",
        "#     else :\n",
        "#       return math.log(0.05*x + 1) + abs(math.log(0.05*kernel + 1) - kernel)\n",
        "\n",
        "\n",
        "# Second convolutional layer\n",
        "concatenated_features_for_l2 = concatenate([x1, input_layer])\n",
        "x2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l2)\n",
        "x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "x2 = tf.keras.layers.Activation(sl_relu)(x2)\n",
        "\n",
        "# Third convolutional layer\n",
        "concatenated_features_for_l3 = concatenate([x2, x1, input_layer])\n",
        "x3 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l3)\n",
        "x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "x3 = tf.keras.layers.Activation(sl_relu)(x3)\n",
        "\n",
        "# Conversion Block\n",
        "x4 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(x3)\n",
        "x4 = tf.keras.layers.Activation(sl_relu)(x4)\n",
        "\n",
        "# Max-pooling layer\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x4)\n",
        "\n",
        "# Dense block 2\n",
        "# First convolutional layer\n",
        "x5 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(pool4)\n",
        "x5 = tf.keras.layers.BatchNormalization()(x5)\n",
        "x5 = tf.keras.layers.Activation(sl_relu)(x5)\n",
        "\n",
        "# Second convolutional layer\n",
        "concatenated_features_for_l6 = concatenate([x5, pool4])\n",
        "x6 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l6)\n",
        "x6 = tf.keras.layers.BatchNormalization()(x6)\n",
        "x6 = tf.keras.layers.Activation(sl_relu)(x6)\n",
        "\n",
        "# Third convolutional layer\n",
        "concatenated_features_for_l7 = concatenate([x5, x6, pool4])\n",
        "x7 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l7)\n",
        "x7 = tf.keras.layers.BatchNormalization()(x7)\n",
        "x7 = tf.keras.layers.Activation(sl_relu)(x7)\n",
        "\n",
        "concatenated_features_for_AF = concatenate([x5,x6,x7, pool4])\n",
        "\n",
        "# Passing it through activation function\n",
        "final_af_val = sl_relu(concatenated_features_for_AF)\n",
        "# Flatten layer\n",
        "flatten = Flatten()(final_af_val)\n",
        "\n",
        "\n",
        "output_layer = Dense(3, activation='softmax')(flatten)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Xx1BQBNTUSCi"
      },
      "outputs": [],
      "source": [
        "optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08)\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7_7e4g-aKHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PYQOtFcBUZy5"
      },
      "outputs": [],
      "source": [
        "no_of_test = X_test.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "vsKZFui7efhV",
        "outputId": "9d00bfdf-c619-4ad6-b401-3c7116936ad1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   path      crop\n",
              "1116  [[[0.7294117647058823, 0.615686274509804, 0.49...  red gram\n",
              "1368  [[[0.6627450980392157, 0.5490196078431373, 0.4...  red gram\n",
              "422   [[[0.18823529411764706, 0.18823529411764706, 0...    cotton\n",
              "413   [[[0.5333333333333333, 0.48627450980392156, 0....    cotton\n",
              "451   [[[0.18823529411764706, 0.25098039215686274, 0...    cotton\n",
              "...                                                 ...       ...\n",
              "983   [[[0.5215686274509804, 0.596078431372549, 0.35...     maize\n",
              "799   [[[0.3607843137254902, 0.4235294117647059, 0.2...     maize\n",
              "1265  [[[0.5098039215686274, 0.403921568627451, 0.30...  red gram\n",
              "1150  [[[0.4470588235294118, 0.44313725490196076, 0....  red gram\n",
              "824   [[[0.4627450980392157, 0.49411764705882355, 0....     maize\n",
              "\n",
              "[300 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa5706a0-7cab-436c-a186-93e78c1914fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>crop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1116</th>\n",
              "      <td>[[[0.7294117647058823, 0.615686274509804, 0.49...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1368</th>\n",
              "      <td>[[[0.6627450980392157, 0.5490196078431373, 0.4...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>[[[0.18823529411764706, 0.18823529411764706, 0...</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>[[[0.5333333333333333, 0.48627450980392156, 0....</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>[[[0.18823529411764706, 0.25098039215686274, 0...</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>[[[0.5215686274509804, 0.596078431372549, 0.35...</td>\n",
              "      <td>maize</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>[[[0.3607843137254902, 0.4235294117647059, 0.2...</td>\n",
              "      <td>maize</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>[[[0.5098039215686274, 0.403921568627451, 0.30...</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1150</th>\n",
              "      <td>[[[0.4470588235294118, 0.44313725490196076, 0....</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>[[[0.4627450980392157, 0.49411764705882355, 0....</td>\n",
              "      <td>maize</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa5706a0-7cab-436c-a186-93e78c1914fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa5706a0-7cab-436c-a186-93e78c1914fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa5706a0-7cab-436c-a186-93e78c1914fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea8db01f-ff19-4ede-8ed7-9c754f735a25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea8db01f-ff19-4ede-8ed7-9c754f735a25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea8db01f-ff19-4ede-8ed7-9c754f735a25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = '/content/drive/MyDrive/x_test_zoomed.csv'\n",
        "X_test.to_csv(csv_file_path, index=False)"
      ],
      "metadata": {
        "id": "rBIHRoQpIBW6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "N-iVdJsKUddH"
      },
      "outputs": [],
      "source": [
        "#similar as done for the training data\n",
        "X_t=[]\n",
        "for x in X_test['path']:\n",
        "    for j in x:\n",
        "        for i in j:\n",
        "            for a in i :\n",
        "                X_t.append(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JzgVa1llUde5"
      },
      "outputs": [],
      "source": [
        "X_t=np.asarray(X_t).reshape(no_of_test,28,28,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytIKvu16UhY5",
        "outputId": "6419de3d-ecaf-450b-f73f-af4284a6038f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "Y_test=to_categorical(y_test,num_classes=3)\n",
        "print(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/x_train_array_zoomed.csv', X)\n",
        "np.save('/content/drive/MyDrive/x_test_array_zoomed.csv', X_t)\n",
        "#How to load\n",
        "# loaded_array = np.load('file_name.npy')\n",
        "\n"
      ],
      "metadata": {
        "id": "HFJpXIvDwkSA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT3niCSmanEV",
        "outputId": "a551060d-48f1-4395-96e1-1c52c3f349a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdqSPGuPHxOx",
        "outputId": "9f9803c5-1209-43b1-c592-c82bc9ec3d1a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 28, 28, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dRhsKrabYbR7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f388888b-a8ee-46c5-c4e2-de7b2b9295d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 17s 46ms/step - loss: 2.0285 - accuracy: 0.8250 - val_loss: 7.4157 - val_accuracy: 0.3500\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.8325 - accuracy: 0.9008 - val_loss: 9.1088 - val_accuracy: 0.5467\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.5062 - accuracy: 0.9225 - val_loss: 7.3934 - val_accuracy: 0.3033\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.7445 - accuracy: 0.9225 - val_loss: 16.1311 - val_accuracy: 0.2867\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.1952 - accuracy: 0.9692 - val_loss: 2.0191 - val_accuracy: 0.6800\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.3051 - accuracy: 0.9542 - val_loss: 4.1121 - val_accuracy: 0.5267\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2173 - accuracy: 0.9633 - val_loss: 8.3129 - val_accuracy: 0.3833\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0791 - accuracy: 0.9783 - val_loss: 5.7295 - val_accuracy: 0.4567\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.2287 - accuracy: 0.9708 - val_loss: 14.3705 - val_accuracy: 0.5033\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.2538 - accuracy: 0.9775 - val_loss: 3.1610 - val_accuracy: 0.6433\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1272 - accuracy: 0.9775 - val_loss: 6.4091 - val_accuracy: 0.6200\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1674 - accuracy: 0.9750 - val_loss: 0.5555 - val_accuracy: 0.9200\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1657 - accuracy: 0.9775 - val_loss: 1.5869 - val_accuracy: 0.8233\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0731 - accuracy: 0.9883 - val_loss: 1.6341 - val_accuracy: 0.8133\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0333 - accuracy: 0.9925 - val_loss: 2.5996 - val_accuracy: 0.7700\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0657 - accuracy: 0.9900 - val_loss: 9.9695 - val_accuracy: 0.7033\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0142 - accuracy: 0.9983 - val_loss: 6.6960 - val_accuracy: 0.7467\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0880 - accuracy: 0.9892 - val_loss: 0.9487 - val_accuracy: 0.9367\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.6112 - val_accuracy: 0.9433\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 5.8249 - val_accuracy: 0.7033\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 3.8066 - val_accuracy: 0.7767\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0243 - accuracy: 0.9950 - val_loss: 6.1159 - val_accuracy: 0.7200\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.9386 - val_accuracy: 0.9567\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 1.6967 - val_accuracy: 0.8867\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0633 - accuracy: 0.9942 - val_loss: 1.5065 - val_accuracy: 0.8767\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.1546 - accuracy: 0.9833 - val_loss: 0.7853 - val_accuracy: 0.9467\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 8.0188e-04 - accuracy: 0.9992 - val_loss: 0.7682 - val_accuracy: 0.9467\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0450 - accuracy: 0.9933 - val_loss: 9.6396 - val_accuracy: 0.7300\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0419 - accuracy: 0.9933 - val_loss: 1.9144 - val_accuracy: 0.9233\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0250 - accuracy: 0.9967 - val_loss: 3.0058 - val_accuracy: 0.7733\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 2.7858 - val_accuracy: 0.8400\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0454 - accuracy: 0.9933 - val_loss: 7.7524 - val_accuracy: 0.7367\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0319 - accuracy: 0.9942 - val_loss: 1.0891 - val_accuracy: 0.9400\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0418 - accuracy: 0.9933 - val_loss: 1.3785 - val_accuracy: 0.9133\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 1.5441 - val_accuracy: 0.8433\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 4.8071e-06 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.9733\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 9.6327e-06 - accuracy: 1.0000 - val_loss: 0.8333 - val_accuracy: 0.9633\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 2.1710e-06 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.9633\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 1.5206e-04 - accuracy: 1.0000 - val_loss: 0.9326 - val_accuracy: 0.9600\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0106 - accuracy: 0.9992 - val_loss: 15.1399 - val_accuracy: 0.6333\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0412 - accuracy: 0.9975 - val_loss: 4.3094 - val_accuracy: 0.8333\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0454 - accuracy: 0.9933 - val_loss: 1.2768 - val_accuracy: 0.9400\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 2.9194 - val_accuracy: 0.9067\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 9.4068 - val_accuracy: 0.5700\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0231 - accuracy: 0.9967 - val_loss: 10.7358 - val_accuracy: 0.7100\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0351 - accuracy: 0.9942 - val_loss: 1.1822 - val_accuracy: 0.9467\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 1.6116e-04 - accuracy: 1.0000 - val_loss: 1.0087 - val_accuracy: 0.9433\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 3.0649e-06 - accuracy: 1.0000 - val_loss: 0.9205 - val_accuracy: 0.9633\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.0185 - accuracy: 0.9967 - val_loss: 1.3056 - val_accuracy: 0.9533\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0188 - accuracy: 0.9983 - val_loss: 2.0035 - val_accuracy: 0.8833\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0259 - accuracy: 0.9975 - val_loss: 1.2806 - val_accuracy: 0.9467\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 1.2278 - val_accuracy: 0.9400\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 2.1673 - val_accuracy: 0.9300\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 1.0866e-05 - accuracy: 1.0000 - val_loss: 2.0922 - val_accuracy: 0.9333\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 9.2515e-07 - accuracy: 1.0000 - val_loss: 1.6644 - val_accuracy: 0.9367\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 1.1593e-07 - accuracy: 1.0000 - val_loss: 1.4142 - val_accuracy: 0.9467\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 5.8904e-07 - accuracy: 1.0000 - val_loss: 1.2117 - val_accuracy: 0.9600\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 4.3014e-08 - accuracy: 1.0000 - val_loss: 1.1661 - val_accuracy: 0.9667\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.8809e-09 - accuracy: 1.0000 - val_loss: 1.1399 - val_accuracy: 0.9667\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 5.0186e-06 - accuracy: 1.0000 - val_loss: 1.2865 - val_accuracy: 0.9333\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.2050e-07 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.9433\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 3.8950e-06 - accuracy: 1.0000 - val_loss: 1.1234 - val_accuracy: 0.9600\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.1088 - accuracy: 0.9925 - val_loss: 1.3356 - val_accuracy: 0.9533\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.0162e-07 - accuracy: 1.0000 - val_loss: 1.2187 - val_accuracy: 0.9567\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0211 - accuracy: 0.9967 - val_loss: 1.3016 - val_accuracy: 0.9233\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 6.8640e-05 - accuracy: 1.0000 - val_loss: 1.0475 - val_accuracy: 0.9633\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 1.0244 - val_accuracy: 0.9500\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.0322 - accuracy: 0.9967 - val_loss: 2.3614 - val_accuracy: 0.8167\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0179 - accuracy: 0.9958 - val_loss: 27.9862 - val_accuracy: 0.6833\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0233 - accuracy: 0.9983 - val_loss: 1.8943 - val_accuracy: 0.9133\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 1.0555 - val_accuracy: 0.8900\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 1.5459e-05 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.9467\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 2.8195e-06 - accuracy: 1.0000 - val_loss: 0.6721 - val_accuracy: 0.9633\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 2.6241 - val_accuracy: 0.9200\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.3709e-06 - accuracy: 1.0000 - val_loss: 2.0354 - val_accuracy: 0.9267\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 1.8421e-05 - accuracy: 1.0000 - val_loss: 1.3741 - val_accuracy: 0.9500\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0181 - accuracy: 0.9983 - val_loss: 1.2766 - val_accuracy: 0.9533\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0151 - accuracy: 0.9983 - val_loss: 3.6179 - val_accuracy: 0.8433\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0235 - accuracy: 0.9983 - val_loss: 0.5915 - val_accuracy: 0.9667\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 9.9341e-10 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.9667\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.4901e-09 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 0.9667\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.2848e-09 - accuracy: 1.0000 - val_loss: 0.7239 - val_accuracy: 0.9633\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0166 - accuracy: 0.9975 - val_loss: 1.8148 - val_accuracy: 0.9333\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 4.5852e-06 - accuracy: 1.0000 - val_loss: 1.2718 - val_accuracy: 0.9433\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 8.5824e-06 - accuracy: 1.0000 - val_loss: 0.9895 - val_accuracy: 0.9600\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 1.9868e-10 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.9600\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 4.1482e-04 - accuracy: 1.0000 - val_loss: 0.9457 - val_accuracy: 0.9633\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 8.0523 - val_accuracy: 0.6900\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 2.1470 - val_accuracy: 0.8600\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.4151e-05 - accuracy: 1.0000 - val_loss: 1.1103 - val_accuracy: 0.9467\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 3.0235e-05 - accuracy: 1.0000 - val_loss: 1.9284 - val_accuracy: 0.9400\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0299 - accuracy: 0.9975 - val_loss: 1.6109 - val_accuracy: 0.9400\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 3.7903e-07 - accuracy: 1.0000 - val_loss: 1.5058 - val_accuracy: 0.9433\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 5.2651e-09 - accuracy: 1.0000 - val_loss: 1.4400 - val_accuracy: 0.9467\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 4.0859e-07 - accuracy: 1.0000 - val_loss: 1.3101 - val_accuracy: 0.9467\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.5238e-07 - accuracy: 1.0000 - val_loss: 1.2506 - val_accuracy: 0.9467\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 6.9538e-09 - accuracy: 1.0000 - val_loss: 1.2392 - val_accuracy: 0.9467\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0166 - accuracy: 0.9983 - val_loss: 1.3601 - val_accuracy: 0.9100\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 2.7463e-04 - accuracy: 1.0000 - val_loss: 1.1369 - val_accuracy: 0.9467\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.1540e-05 - accuracy: 1.0000 - val_loss: 1.6150 - val_accuracy: 0.9433\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "history = model.fit(X, Y, epochs=100, validation_data=(X_t, Y_test))\n",
        "\n",
        "# Plot the accuracy vs. epoch graph\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_relu.fit(X, Y, epochs=100, validation_data=(X_t, Y_test))\n",
        "\n",
        "# Plot the accuracy vs. epoch graph\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tPcWGZutBl8E",
        "outputId": "be8036dd-2c53-4131-bae1-f6f97eb4640f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9983 - val_loss: 0.4444 - val_accuracy: 0.9133\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.0458 - accuracy: 0.9958 - val_loss: 0.9814 - val_accuracy: 0.7633\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 1s 31ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.3157 - val_accuracy: 0.9300\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 0.0335 - accuracy: 0.9933 - val_loss: 0.3837 - val_accuracy: 0.9567\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.0189 - accuracy: 0.9975 - val_loss: 0.1679 - val_accuracy: 0.9700\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.2498 - val_accuracy: 0.9800\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.2980 - val_accuracy: 0.9633\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9700\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 0.4196 - val_accuracy: 0.9367\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.4641 - val_accuracy: 0.9633\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0265 - accuracy: 0.9942 - val_loss: 0.5762 - val_accuracy: 0.9533\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.3061 - val_accuracy: 0.9767\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.0035 - accuracy: 0.9975 - val_loss: 0.5397 - val_accuracy: 0.9567\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.0188 - accuracy: 0.9958 - val_loss: 0.5192 - val_accuracy: 0.9667\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.3840 - val_accuracy: 0.9767\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.4260 - val_accuracy: 0.9767\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.4767 - val_accuracy: 0.9667\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 6.1045e-04 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.9633\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.2542 - val_accuracy: 0.9667\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.9900 - val_accuracy: 0.9133\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.0194 - accuracy: 0.9975 - val_loss: 0.6269 - val_accuracy: 0.9467\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.0046 - accuracy: 0.9975 - val_loss: 1.1189 - val_accuracy: 0.9033\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.0242 - accuracy: 0.9950 - val_loss: 0.6753 - val_accuracy: 0.9533\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.0441 - accuracy: 0.9933 - val_loss: 0.5187 - val_accuracy: 0.9567\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 3.6659e-04 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9600\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.3563 - val_accuracy: 0.9700\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.1954e-04 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9700\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 0.9992 - val_loss: 0.3939 - val_accuracy: 0.9667\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 0.3673 - val_accuracy: 0.9800\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.9975 - val_loss: 0.5667 - val_accuracy: 0.9767\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0398 - accuracy: 0.9942 - val_loss: 0.2082 - val_accuracy: 0.9800\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.4556 - val_accuracy: 0.9767\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 0.2387 - val_accuracy: 0.9767\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0404 - accuracy: 0.9967 - val_loss: 0.2602 - val_accuracy: 0.9733\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 0.3478 - val_accuracy: 0.9733\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.3884 - val_accuracy: 0.9667\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.4413 - val_accuracy: 0.9600\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 4.5950e-05 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9667\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.0531e-04 - accuracy: 1.0000 - val_loss: 0.4634 - val_accuracy: 0.9733\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 0.9983 - val_loss: 0.5636 - val_accuracy: 0.9633\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 2.7095e-05 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9667\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 0.6097 - val_accuracy: 0.9800\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.1509e-04 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 0.9733\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.5511 - val_accuracy: 0.9733\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 6.1071e-05 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 0.9733\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.6604 - val_accuracy: 0.9533\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.4110 - val_accuracy: 0.9700\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 6.5038e-06 - accuracy: 1.0000 - val_loss: 0.4612 - val_accuracy: 0.9700\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.7169 - val_accuracy: 0.9200\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0069 - accuracy: 0.9967 - val_loss: 0.4462 - val_accuracy: 0.9767\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 1.0195e-04 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.9700\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 7.4188e-05 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9800\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.2572 - val_accuracy: 0.9767\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 6.2880e-06 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9767\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 4.2534e-06 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.9767\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.5155 - val_accuracy: 0.9633\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.0141 - accuracy: 0.9983 - val_loss: 0.5379 - val_accuracy: 0.9667\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.9388e-04 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9600\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 9.2202e-05 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.9767\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.7112 - val_accuracy: 0.9800\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9992 - val_loss: 0.5476 - val_accuracy: 0.9767\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.7076 - val_accuracy: 0.9633\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.9733\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.7362 - val_accuracy: 0.9700\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 7.5008e-04 - accuracy: 0.9992 - val_loss: 0.5886 - val_accuracy: 0.9733\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 0.3639 - val_accuracy: 0.9367\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9975 - val_loss: 0.4139 - val_accuracy: 0.9800\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9967 - val_loss: 0.4978 - val_accuracy: 0.9700\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.3962 - val_accuracy: 0.9767\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 0.9983 - val_loss: 0.3569 - val_accuracy: 0.9800\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.3440 - val_accuracy: 0.9767\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.4890 - val_accuracy: 0.9667\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 4.3128e-04 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.9700\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9967 - val_loss: 0.6413 - val_accuracy: 0.9600\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.4520 - val_accuracy: 0.9733\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.5367 - val_accuracy: 0.9733\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 3.9060e-06 - accuracy: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.9733\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 4.7964e-06 - accuracy: 1.0000 - val_loss: 0.5979 - val_accuracy: 0.9733\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.4978 - val_accuracy: 0.9767\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.6462 - val_accuracy: 0.9600\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.5796 - val_accuracy: 0.9700\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 2.0503e-04 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.9733\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 3.5574e-05 - accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.9800\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.7202 - val_accuracy: 0.9733\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0083 - accuracy: 0.9967 - val_loss: 0.4764 - val_accuracy: 0.9800\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.4763 - val_accuracy: 0.9800\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 4.7036e-04 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.9800\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.0345 - accuracy: 0.9958 - val_loss: 0.8963 - val_accuracy: 0.9500\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 3.1920e-05 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.9567\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 1.1236 - val_accuracy: 0.9433\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9967 - val_loss: 0.4800 - val_accuracy: 0.9733\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 2.3674e-04 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9667\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 2.3574e-04 - accuracy: 1.0000 - val_loss: 0.5411 - val_accuracy: 0.9733\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.7083 - val_accuracy: 0.9767\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 2.1015e-06 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.9767\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 2.0699e-04 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.9733\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 1.6260e-05 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9733\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.7324 - val_accuracy: 0.9633\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 0.6779 - val_accuracy: 0.9667\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 6.8266e-06 - accuracy: 1.0000 - val_loss: 0.6260 - val_accuracy: 0.9733\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr0GBwvJfyv2",
        "outputId": "e0df9a68-ba87-49ed-9594-03ab6bf67529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 9ms/step\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "2 -> 1\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "2 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 1\n",
            "0 -> 0\n",
            "2 -> 1\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 0\n",
            "2 -> 1\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "2 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "2 -> 0\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 1\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "1 -> 0\n",
            "2 -> 2\n",
            "2 -> 1\n",
            "2 -> 2\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "1 -> 1\n",
            "1 -> 0\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "2 -> 2\n",
            "0 -> 0\n",
            "0 -> 0\n",
            "2 -> 2\n",
            "94.33333333333334\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "\n",
        "#print(len(X_t))\n",
        "for row_idx, (row, r1) in enumerate(zip(model.predict(X_t),Y_test)):\n",
        "    # Find the index of the maximum value in the row\n",
        "    max_col_idx = np.argmax(row)\n",
        "    max_colu_idx = np.argmax(r1)\n",
        "    if max_col_idx == max_colu_idx:\n",
        "      count+=1\n",
        "      result = str(max_col_idx) + \" -> \" +  str( max_colu_idx)\n",
        "      print(result)\n",
        "    else:\n",
        "       result = str(max_col_idx) + \" -> \" +  str( max_colu_idx)\n",
        "       print(result)\n",
        "print (count/300 * 100)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding the Dropout layer"
      ],
      "metadata": {
        "id": "t2OrLyU1fUNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#New sl-relu\n",
        "\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense, concatenate, BatchNormalization, Activation, MaxPooling2D\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "# input layer\n",
        "input_layer = Input(shape=(28, 28, 3))\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "def sl_relu(x):\n",
        "    # Define the threshold\n",
        "    threshold = 0.05\n",
        "\n",
        "    # Apply the custom activation function element-wise using TensorFlow operations\n",
        "    condition = tf.math.less(x, 0)\n",
        "    abs_x = tf.abs(x)\n",
        "    log_term = tf.math.log(threshold * x + 1) + tf.abs(tf.math.log(threshold * abs_x + 1) - abs_x)\n",
        "\n",
        "    return tf.where(condition, x / (1 + abs_x), tf.where(tf.math.less_equal(x, 1), x, log_term))\n",
        "\n",
        "\n",
        "\n",
        "# First convolutional layer\n",
        "x1 = Conv2D(32, (3, 3), padding='same')(Conv2D(32, (3, 3), padding='same')(input_layer))\n",
        "x1 = BatchNormalization()(x1)\n",
        "x1 = Activation(sl_relu)(x1)\n",
        "\n",
        "# # SL - ReLU activation function\n",
        "# def sl_relu(x) :\n",
        "#   # Convolutional layer's output\n",
        "#   conv_output = x\n",
        "\n",
        "#   # Convolutional layer's kernel\n",
        "#   conv_layer = x.op.inputs[0]\n",
        "#   kernel = conv_layer.kernel\n",
        "\n",
        "#   if x < 0 :\n",
        "#     return x/ 1 + abs(x)\n",
        "#   else :\n",
        "#     if x <= kernel :\n",
        "#       return x\n",
        "#     else :\n",
        "#       return math.log(0.05*x + 1) + abs(math.log(0.05*kernel + 1) - kernel)\n",
        "\n",
        "\n",
        "# Second convolutional layer\n",
        "concatenated_features_for_l2 = concatenate([x1, input_layer])\n",
        "x2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l2)\n",
        "x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "x2 = tf.keras.layers.Activation(sl_relu)(x2)\n",
        "\n",
        "# Third convolutional layer\n",
        "concatenated_features_for_l3 = concatenate([x2, x1, input_layer])\n",
        "x3 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l3)\n",
        "x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "x3 = tf.keras.layers.Activation(sl_relu)(x3)\n",
        "\n",
        "# Conversion Block\n",
        "x4 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(x3)\n",
        "x4 = tf.keras.layers.Activation(sl_relu)(x4)\n",
        "\n",
        "# Max-pooling layer\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x4)\n",
        "# Dropout layer\n",
        "dropout1 = Dropout(0.25)(pool4)\n",
        "\n",
        "\n",
        "# Dense block 2\n",
        "# First convolutional layer\n",
        "x5 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(dropout1)\n",
        "x5 = tf.keras.layers.BatchNormalization()(x5)\n",
        "x5 = tf.keras.layers.Activation(sl_relu)(x5)\n",
        "\n",
        "# Second convolutional layer\n",
        "concatenated_features_for_l6 = concatenate([x5, dropout1])\n",
        "x6 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l6)\n",
        "x6 = tf.keras.layers.BatchNormalization()(x6)\n",
        "x6 = tf.keras.layers.Activation(sl_relu)(x6)\n",
        "\n",
        "# Third convolutional layer\n",
        "concatenated_features_for_l7 = concatenate([x5, x6, dropout1])\n",
        "x7 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l7)\n",
        "x7 = tf.keras.layers.BatchNormalization()(x7)\n",
        "x7 = tf.keras.layers.Activation(sl_relu)(x7)\n",
        "\n",
        "concatenated_features_for_AF = concatenate([x5,x6,x7, dropout1])\n",
        "\n",
        "# Passing it through activation function\n",
        "final_af_val = sl_relu(concatenated_features_for_AF)\n",
        "# Flatten layer\n",
        "flatten = Flatten()(final_af_val)\n",
        "\n",
        "\n",
        "output_layer = Dense(3, activation='softmax')(flatten)\n",
        "\n",
        "# Create the model\n",
        "model_dropout = Model(inputs=input_layer, outputs=output_layer)\n"
      ],
      "metadata": {
        "id": "tFq4A2m4fSte"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08)\n",
        "model_dropout.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "MmNEvaBBiE2j"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_dropout.fit(X, Y, epochs=100, validation_data=(X_t, Y_test))\n",
        "\n",
        "# Plot the accuracy vs. epoch graph\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iWkZ9Lnbh-29",
        "outputId": "83dda37b-34db-4e27-db9c-46271e5c20fb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 57s 45ms/step - loss: 1.5435 - accuracy: 0.8300 - val_loss: 2.0372 - val_accuracy: 0.6033\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.5473 - accuracy: 0.9183 - val_loss: 3.9199 - val_accuracy: 0.5433\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.8213 - accuracy: 0.9100 - val_loss: 15.5330 - val_accuracy: 0.2900\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.2752 - accuracy: 0.9642 - val_loss: 7.9773 - val_accuracy: 0.5100\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.3144 - accuracy: 0.9525 - val_loss: 8.5143 - val_accuracy: 0.3833\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.2864 - accuracy: 0.9575 - val_loss: 15.3208 - val_accuracy: 0.2900\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.1604 - accuracy: 0.9700 - val_loss: 13.7960 - val_accuracy: 0.2967\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.1950 - accuracy: 0.9650 - val_loss: 3.5837 - val_accuracy: 0.6000\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1506 - accuracy: 0.9758 - val_loss: 3.6929 - val_accuracy: 0.6433\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.1050 - accuracy: 0.9800 - val_loss: 1.7547 - val_accuracy: 0.8700\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.1139 - accuracy: 0.9758 - val_loss: 0.6354 - val_accuracy: 0.9367\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0751 - accuracy: 0.9817 - val_loss: 8.8422 - val_accuracy: 0.6200\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.1279 - accuracy: 0.9817 - val_loss: 1.4505 - val_accuracy: 0.8733\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.1112 - accuracy: 0.9792 - val_loss: 1.1863 - val_accuracy: 0.8800\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0285 - accuracy: 0.9925 - val_loss: 1.0641 - val_accuracy: 0.9233\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.1364 - accuracy: 0.9750 - val_loss: 2.7901 - val_accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0849 - accuracy: 0.9875 - val_loss: 1.0321 - val_accuracy: 0.9367\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0380 - accuracy: 0.9892 - val_loss: 10.2804 - val_accuracy: 0.5600\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0770 - accuracy: 0.9900 - val_loss: 2.5833 - val_accuracy: 0.8867\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0234 - accuracy: 0.9983 - val_loss: 12.5529 - val_accuracy: 0.6833\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.0404 - accuracy: 0.9933 - val_loss: 1.2493 - val_accuracy: 0.9000\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.0359 - accuracy: 0.9933 - val_loss: 5.2112 - val_accuracy: 0.7700\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0967 - accuracy: 0.9858 - val_loss: 0.9011 - val_accuracy: 0.9300\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0590 - accuracy: 0.9883 - val_loss: 7.3755 - val_accuracy: 0.7333\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0599 - accuracy: 0.9875 - val_loss: 1.5757 - val_accuracy: 0.9133\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0465 - accuracy: 0.9942 - val_loss: 1.1483 - val_accuracy: 0.9367\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0055 - accuracy: 0.9967 - val_loss: 4.5636 - val_accuracy: 0.7233\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0890 - accuracy: 0.9867 - val_loss: 3.6275 - val_accuracy: 0.7900\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0308 - accuracy: 0.9917 - val_loss: 4.3081 - val_accuracy: 0.7700\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0398 - accuracy: 0.9933 - val_loss: 0.6882 - val_accuracy: 0.9533\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0538 - accuracy: 0.9892 - val_loss: 38.5965 - val_accuracy: 0.3767\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0549 - accuracy: 0.9917 - val_loss: 7.2747 - val_accuracy: 0.7233\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0217 - accuracy: 0.9958 - val_loss: 9.4564 - val_accuracy: 0.6900\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0237 - accuracy: 0.9950 - val_loss: 0.9009 - val_accuracy: 0.9433\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0390 - accuracy: 0.9950 - val_loss: 17.4842 - val_accuracy: 0.6833\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 4.2128 - val_accuracy: 0.7833\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0341 - accuracy: 0.9925 - val_loss: 3.7861 - val_accuracy: 0.7800\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.0336 - accuracy: 0.9967 - val_loss: 5.7734 - val_accuracy: 0.7667\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.1175 - accuracy: 0.9950 - val_loss: 0.7207 - val_accuracy: 0.9367\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.8564 - val_accuracy: 0.9333\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.0273 - accuracy: 0.9950 - val_loss: 6.8402 - val_accuracy: 0.7467\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 2.0375e-05 - accuracy: 1.0000 - val_loss: 2.1293 - val_accuracy: 0.8800\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0502 - accuracy: 0.9933 - val_loss: 1.5273 - val_accuracy: 0.8933\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 4.1311e-06 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.9433\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0377 - accuracy: 0.9933 - val_loss: 0.6774 - val_accuracy: 0.9467\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0177 - accuracy: 0.9975 - val_loss: 1.3135 - val_accuracy: 0.9533\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0379 - accuracy: 0.9950 - val_loss: 3.6316 - val_accuracy: 0.8167\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 1.0162 - val_accuracy: 0.9400\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 1.1782 - val_accuracy: 0.9300\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0276 - accuracy: 0.9967 - val_loss: 1.0018 - val_accuracy: 0.9367\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 1.3052 - val_accuracy: 0.9300\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 2.9248 - val_accuracy: 0.8267\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0793 - accuracy: 0.9892 - val_loss: 9.8605 - val_accuracy: 0.7267\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0133 - accuracy: 0.9975 - val_loss: 1.3940 - val_accuracy: 0.8933\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.0298 - accuracy: 0.9975 - val_loss: 14.0672 - val_accuracy: 0.6700\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 23.1699 - val_accuracy: 0.6333\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.8672 - val_accuracy: 0.9500\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 1s 29ms/step - loss: 0.0533 - accuracy: 0.9967 - val_loss: 2.0598 - val_accuracy: 0.9000\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 8.1634 - val_accuracy: 0.7333\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0205 - accuracy: 0.9975 - val_loss: 5.5309 - val_accuracy: 0.7767\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 1.6986 - val_accuracy: 0.9100\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 2.2777e-06 - accuracy: 1.0000 - val_loss: 1.1843 - val_accuracy: 0.9433\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 18.5881 - val_accuracy: 0.5567\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 1.2947 - val_accuracy: 0.9600\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0077 - accuracy: 0.9967 - val_loss: 5.3549 - val_accuracy: 0.8200\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0339 - accuracy: 0.9975 - val_loss: 2.1330 - val_accuracy: 0.8700\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 8.4766e-04 - accuracy: 1.0000 - val_loss: 6.1674 - val_accuracy: 0.7633\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0260 - accuracy: 0.9950 - val_loss: 4.1875 - val_accuracy: 0.8367\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 4.4836 - val_accuracy: 0.8167\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0468 - accuracy: 0.9958 - val_loss: 1.3510 - val_accuracy: 0.9500\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 4.0416e-06 - accuracy: 1.0000 - val_loss: 1.2570 - val_accuracy: 0.9600\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 2.2618e-07 - accuracy: 1.0000 - val_loss: 1.2421 - val_accuracy: 0.9600\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 9.0020e-07 - accuracy: 1.0000 - val_loss: 1.1702 - val_accuracy: 0.9567\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0384 - accuracy: 0.9975 - val_loss: 7.2453 - val_accuracy: 0.7467\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 1.4809 - val_accuracy: 0.9500\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 2.3599 - val_accuracy: 0.8500\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 0.0187 - accuracy: 0.9992 - val_loss: 1.4841 - val_accuracy: 0.9400\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 1.5304 - val_accuracy: 0.9467\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.2712e-06 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.9433\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.9500\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 1.8545e-07 - accuracy: 1.0000 - val_loss: 1.1242 - val_accuracy: 0.9433\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 5.7270e-04 - accuracy: 1.0000 - val_loss: 1.0898 - val_accuracy: 0.9533\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 3.0776e-04 - accuracy: 1.0000 - val_loss: 7.7584 - val_accuracy: 0.7833\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 3.1298 - val_accuracy: 0.8633\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.0391 - accuracy: 0.9975 - val_loss: 1.4708 - val_accuracy: 0.9467\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 10.0969 - val_accuracy: 0.7033\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0335 - accuracy: 0.9975 - val_loss: 1.6701 - val_accuracy: 0.9433\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 7.0943e-06 - accuracy: 1.0000 - val_loss: 1.4012 - val_accuracy: 0.9433\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 1.8088e-06 - accuracy: 1.0000 - val_loss: 1.7922 - val_accuracy: 0.9500\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 2.3340 - val_accuracy: 0.9233\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 1s 26ms/step - loss: 2.5431e-08 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.9367\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 1.8674e-07 - accuracy: 1.0000 - val_loss: 1.8348 - val_accuracy: 0.9433\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 1.2860 - val_accuracy: 0.9233\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 1s 27ms/step - loss: 1.6093e-08 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.9500\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 1s 25ms/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 0.9642 - val_accuracy: 0.9633\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 5.7618e-09 - accuracy: 1.0000 - val_loss: 1.0012 - val_accuracy: 0.9667\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.7850e-06 - accuracy: 1.0000 - val_loss: 5.7172 - val_accuracy: 0.8067\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 1s 24ms/step - loss: 0.0160 - accuracy: 0.9975 - val_loss: 5.4902 - val_accuracy: 0.7933\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 1.6105 - val_accuracy: 0.9200\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 6.2585e-09 - accuracy: 1.0000 - val_loss: 1.3685 - val_accuracy: 0.9467\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leaky ReLU AF"
      ],
      "metadata": {
        "id": "j0crCeBENWMU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "GTLoR_6aNclt"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense, concatenate, BatchNormalization, Activation, MaxPooling2D\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "# input layer\n",
        "input_layer = Input(shape=(28, 28, 3))\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "\n",
        "# First convolutional layer\n",
        "x1 = Conv2D(32, (3, 3), padding='same')(Conv2D(32, (3, 3), padding='same')(input_layer))\n",
        "x1 = BatchNormalization()(x1)\n",
        "x1 = LeakyReLU(alpha=0.3)(x1)\n",
        "\n",
        "# # SL - ReLU activation function\n",
        "# def sl_relu(x) :\n",
        "#   # Convolutional layer's output\n",
        "#   conv_output = x\n",
        "\n",
        "#   # Convolutional layer's kernel\n",
        "#   conv_layer = x.op.inputs[0]\n",
        "#   kernel = conv_layer.kernel\n",
        "\n",
        "#   if x < 0 :\n",
        "#     return x/ 1 + abs(x)\n",
        "#   else :\n",
        "#     if x <= kernel :\n",
        "#       return x\n",
        "#     else :\n",
        "#       return math.log(0.05*x + 1) + abs(math.log(0.05*kernel + 1) - kernel)\n",
        "\n",
        "\n",
        "# Second convolutional layer\n",
        "concatenated_features_for_l2 = concatenate([x1, input_layer])\n",
        "x2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l2)\n",
        "x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "x2 = LeakyReLU(alpha=0.3)(x2)\n",
        "\n",
        "# Third convolutional layer\n",
        "concatenated_features_for_l3 = concatenate([x2, x1, input_layer])\n",
        "x3 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l3)\n",
        "x3 = tf.keras.layers.BatchNormalization()(x3)\n",
        "x3 = LeakyReLU(alpha=0.3)(x3)\n",
        "\n",
        "# Conversion Block\n",
        "x4 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(x3)\n",
        "x4 = LeakyReLU(alpha=0.3)(x4)\n",
        "\n",
        "# Max-pooling layer\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x4)\n",
        "\n",
        "# Dense block 2\n",
        "# First convolutional layer\n",
        "x5 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(pool4)\n",
        "x5 = tf.keras.layers.BatchNormalization()(x5)\n",
        "x5 = LeakyReLU(alpha=0.3)(x5)\n",
        "\n",
        "# Second convolutional layer\n",
        "concatenated_features_for_l6 = concatenate([x5, pool4])\n",
        "x6 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l6)\n",
        "x6 = tf.keras.layers.BatchNormalization()(x6)\n",
        "x6 = LeakyReLU(alpha=0.3)(x6)\n",
        "\n",
        "# Third convolutional layer\n",
        "concatenated_features_for_l7 = concatenate([x5, x6, pool4])\n",
        "x7 = tf.keras.layers.Conv2D(32, (3, 3), padding='same')(concatenated_features_for_l7)\n",
        "x7 = tf.keras.layers.BatchNormalization()(x7)\n",
        "x7 = LeakyReLU(alpha=0.3)(x7)\n",
        "\n",
        "concatenated_features_for_AF = concatenate([x5,x6,x7, pool4])\n",
        "\n",
        "# Passing it through activation function\n",
        "final_af_val = LeakyReLU(alpha=0.3)(concatenated_features_for_AF)\n",
        "# Flatten layer\n",
        "flatten = Flatten()(final_af_val)\n",
        "\n",
        "\n",
        "output_layer = Dense(3, activation='softmax')(flatten)\n",
        "\n",
        "# Create the model\n",
        "model_leakyReLU = Model(inputs=input_layer, outputs=output_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08)\n",
        "model_leakyReLU.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "yf1FnMqFOYGm"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_leakyReLU.fit(X, Y, epochs=100, validation_data=(X_t, Y_test))\n",
        "\n",
        "# Plot the accuracy vs. epoch graph\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ksg8-J92Oa-Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68ff0f74-2d98-40be-e7af-241ea4e9cb8d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.2292 - accuracy: 0.9325 - val_loss: 3.2226 - val_accuracy: 0.5833\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.6432 - accuracy: 0.9275 - val_loss: 4.2479 - val_accuracy: 0.2900\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.1673 - accuracy: 0.9575 - val_loss: 3.1592 - val_accuracy: 0.3000\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.0980 - accuracy: 0.9708 - val_loss: 3.1979 - val_accuracy: 0.3100\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 2s 41ms/step - loss: 0.0982 - accuracy: 0.9708 - val_loss: 8.0455 - val_accuracy: 0.2967\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.1848 - accuracy: 0.9775 - val_loss: 8.6833 - val_accuracy: 0.2867\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 1s 32ms/step - loss: 0.1507 - accuracy: 0.9733 - val_loss: 3.2856 - val_accuracy: 0.6200\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 1s 28ms/step - loss: 0.0619 - accuracy: 0.9842 - val_loss: 5.6791 - val_accuracy: 0.3000\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 0.0308 - accuracy: 0.9933 - val_loss: 11.4203 - val_accuracy: 0.3700\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0904 - accuracy: 0.9900 - val_loss: 1.2643 - val_accuracy: 0.7967\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0546 - accuracy: 0.9850 - val_loss: 0.7822 - val_accuracy: 0.8833\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9908 - val_loss: 1.3310 - val_accuracy: 0.8667\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9942 - val_loss: 0.2838 - val_accuracy: 0.9567\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0545 - accuracy: 0.9892 - val_loss: 0.3315 - val_accuracy: 0.9600\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0899 - accuracy: 0.9892 - val_loss: 0.6643 - val_accuracy: 0.9400\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 1.4300 - val_accuracy: 0.9267\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9257 - val_accuracy: 0.9233\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.9925 - val_loss: 2.7791 - val_accuracy: 0.8500\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.0658 - accuracy: 0.9908 - val_loss: 6.4330 - val_accuracy: 0.7300\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.0318 - accuracy: 0.9958 - val_loss: 0.4607 - val_accuracy: 0.9667\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 0.7274 - val_accuracy: 0.9600\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 1.7176 - val_accuracy: 0.8967\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.1429 - accuracy: 0.9900 - val_loss: 72.2575 - val_accuracy: 0.4000\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9967 - val_loss: 5.1909 - val_accuracy: 0.6600\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 6.6645e-06 - accuracy: 1.0000 - val_loss: 1.1731 - val_accuracy: 0.8567\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 1.3403 - val_accuracy: 0.8067\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 1.6031 - val_accuracy: 0.9000\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0652 - accuracy: 0.9958 - val_loss: 3.1493 - val_accuracy: 0.8400\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0287 - accuracy: 0.9925 - val_loss: 0.5448 - val_accuracy: 0.9300\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0396 - accuracy: 0.9958 - val_loss: 4.5962 - val_accuracy: 0.8600\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 1.4292 - val_accuracy: 0.8000\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 3.0582e-05 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9400\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 1.0137 - val_accuracy: 0.8833\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 3.2154e-04 - accuracy: 1.0000 - val_loss: 1.2835 - val_accuracy: 0.8333\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 4.5920 - val_accuracy: 0.8067\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 5.3434e-04 - accuracy: 1.0000 - val_loss: 1.6659 - val_accuracy: 0.8567\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 8.8802 - val_accuracy: 0.7900\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0463 - accuracy: 0.9933 - val_loss: 2.0140 - val_accuracy: 0.9100\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 1.7142 - val_accuracy: 0.7933\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.0055 - accuracy: 0.9958 - val_loss: 1.3281 - val_accuracy: 0.9000\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9975 - val_loss: 0.6604 - val_accuracy: 0.9600\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.0059e-05 - accuracy: 1.0000 - val_loss: 0.6726 - val_accuracy: 0.9600\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.8948 - val_accuracy: 0.9467\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.7358 - val_accuracy: 0.9333\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 5.3254e-05 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.9633\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 0.9992 - val_loss: 1.6476 - val_accuracy: 0.9167\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.4597e-04 - accuracy: 1.0000 - val_loss: 3.3611 - val_accuracy: 0.8767\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 7.7211e-05 - accuracy: 1.0000 - val_loss: 0.9612 - val_accuracy: 0.9433\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 5.1359e-07 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.9500\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0874 - accuracy: 0.9925 - val_loss: 0.5401 - val_accuracy: 0.9367\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 2.6093 - val_accuracy: 0.7800\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 5.3528e-04 - accuracy: 1.0000 - val_loss: 1.2345 - val_accuracy: 0.8667\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.8954 - val_accuracy: 0.9433\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 2.0810 - val_accuracy: 0.8233\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 5.0584e-06 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.9500\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.2901e-05 - accuracy: 1.0000 - val_loss: 0.8254 - val_accuracy: 0.9600\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 1.4441e-06 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.9567\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.5228e-06 - accuracy: 1.0000 - val_loss: 0.6886 - val_accuracy: 0.9567\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.7007e-07 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.9600\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 3.0913e-07 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.9567\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 5.5365e-07 - accuracy: 1.0000 - val_loss: 0.8459 - val_accuracy: 0.9533\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 3.6850e-07 - accuracy: 1.0000 - val_loss: 0.9340 - val_accuracy: 0.9433\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 3.8281e-06 - accuracy: 1.0000 - val_loss: 1.8347 - val_accuracy: 0.8667\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 6.4881e-06 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.9400\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 3.7054e-04 - accuracy: 1.0000 - val_loss: 2.0326 - val_accuracy: 0.9000\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 7.3913e-06 - accuracy: 1.0000 - val_loss: 1.6513 - val_accuracy: 0.9067\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 1.1440 - val_accuracy: 0.9433\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 2.9898 - val_accuracy: 0.7367\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.0537 - accuracy: 0.9975 - val_loss: 1.0495 - val_accuracy: 0.9000\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.8359 - val_accuracy: 0.9333\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.9691 - val_accuracy: 0.9233\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 4.2821 - val_accuracy: 0.7900\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.9710 - val_accuracy: 0.9467\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.8950 - val_accuracy: 0.9567\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9983 - val_loss: 1.8554 - val_accuracy: 0.8367\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 1.3111 - val_accuracy: 0.9533\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 3.6889e-05 - accuracy: 1.0000 - val_loss: 0.9378 - val_accuracy: 0.9600\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 2.4596 - val_accuracy: 0.8600\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0291 - accuracy: 0.9950 - val_loss: 5.4209 - val_accuracy: 0.7567\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 1.5659 - val_accuracy: 0.9500\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 7.4108 - val_accuracy: 0.7033\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.6860e-06 - accuracy: 1.0000 - val_loss: 2.4143 - val_accuracy: 0.8333\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 4.9315e-07 - accuracy: 1.0000 - val_loss: 1.3450 - val_accuracy: 0.9500\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 1.5328e-07 - accuracy: 1.0000 - val_loss: 1.2271 - val_accuracy: 0.9633\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 5.5821e-07 - accuracy: 1.0000 - val_loss: 1.1413 - val_accuracy: 0.9633\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.6590e-08 - accuracy: 1.0000 - val_loss: 1.1592 - val_accuracy: 0.9633\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 3.7148e-07 - accuracy: 1.0000 - val_loss: 1.2566 - val_accuracy: 0.9533\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 1.3014e-08 - accuracy: 1.0000 - val_loss: 1.2507 - val_accuracy: 0.9567\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 9.1291e-08 - accuracy: 1.0000 - val_loss: 1.2404 - val_accuracy: 0.9567\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 4.7037e-07 - accuracy: 1.0000 - val_loss: 1.3037 - val_accuracy: 0.9567\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 3.6034e-06 - accuracy: 1.0000 - val_loss: 1.5074 - val_accuracy: 0.9367\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 1.0597e-06 - accuracy: 1.0000 - val_loss: 1.3861 - val_accuracy: 0.9467\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 2.0025e-07 - accuracy: 1.0000 - val_loss: 1.2141 - val_accuracy: 0.9600\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 6.4108e-07 - accuracy: 1.0000 - val_loss: 1.2099 - val_accuracy: 0.9533\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 9.6459e-08 - accuracy: 1.0000 - val_loss: 1.1822 - val_accuracy: 0.9567\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 1.6391e-08 - accuracy: 1.0000 - val_loss: 1.1626 - val_accuracy: 0.9600\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 4.4802e-08 - accuracy: 1.0000 - val_loss: 1.1486 - val_accuracy: 0.9600\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 2.3383e-07 - accuracy: 1.0000 - val_loss: 1.1236 - val_accuracy: 0.9633\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 1.3113e-08 - accuracy: 1.0000 - val_loss: 1.1303 - val_accuracy: 0.9633\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 2.2153e-08 - accuracy: 1.0000 - val_loss: 1.1337 - val_accuracy: 0.9633\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the dataset 150 x 150"
      ],
      "metadata": {
        "id": "QnC1gxOiK-ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def path_to_RGB_other(path :str):\n",
        "   path=path.replace('/input','/input/agriculture-crop-images/crop_images')\n",
        "   img = Image.open(path)\n",
        "   img = img.resize((150, 150))\n",
        "   img_arr = np.array(img)\n",
        "   img_arr = img_arr.reshape(150,150,3)\n",
        "   print(img_arr.shape)\n",
        "   return img_arr\n",
        "\n",
        "def path_to_RGB_test_other(path :str):\n",
        "   img = Image.open(path)\n",
        "   img = img.resize((150, 150))\n",
        "   img_arr = np.array(img)\n",
        "   img_arr = img_arr.reshape(150,150,3)\n",
        "   return img_arr"
      ],
      "metadata": {
        "id": "zHLP5e9ULDuX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_other, X_test_other, y_train_other, y_test_other = train_test_split(data.drop(columns=['label']), data['label'] , test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cbh_4PSbLcei"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leiiKxuwMvrt",
        "outputId": "3f664f6f-4543-498f-bbed-6c2f6ba836c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n",
            "(150, 150, 3)\n"
          ]
        }
      ],
      "source": [
        "X_train_other['path']=X_train_other['path'].apply(path_to_RGB_other)\n",
        "X_test_other['path']=X_test_other['path'].apply(path_to_RGB_test_other)\n",
        "X_train_other['path']=X_train_other['path']/255\n",
        "X_test_other['path']=X_test_other['path']/255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = '/content/drive/MyDrive/x_train_other_resnet.csv'\n",
        "X_train_other.to_csv(csv_file_path, index=False)"
      ],
      "metadata": {
        "id": "7UR5LzH6SsX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = '/content/drive/MyDrive/x_test_other_resnet.csv'\n",
        "X_test_other.to_csv(csv_file_path, index=False)"
      ],
      "metadata": {
        "id": "BeR58nD3TN5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DDKpkL8CMvr0"
      },
      "outputs": [],
      "source": [
        "no_of_train_other = X_train_other['path'].shape[0]\n",
        "no_of_test_other = X_test_other['path'].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Ism1Jb2zMvr1"
      },
      "outputs": [],
      "source": [
        "X_other=[]\n",
        "for x in X_train_other['path']:\n",
        "    for j in x:\n",
        "        for i in j:\n",
        "            for a in i :\n",
        "                X_other.append(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "9LVoEaXBMvr1"
      },
      "outputs": [],
      "source": [
        "X_other=np.asarray(X_other).reshape(no_of_train_other,150,150,3)\n",
        "Y_other=y_train_other\n",
        "Y_other=to_categorical(Y_other,num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/x_train_other_array_zoomed.csv', X_other)\n",
        "\n",
        "#How to load\n",
        "# loaded_array = np.load('file_name.npy')"
      ],
      "metadata": {
        "id": "C9anRvN12GtA"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# save numpy array as csv file\n",
        "from numpy import asarray\n",
        "from numpy import savetxt, loadtxt"
      ],
      "metadata": {
        "id": "SMD3XRSm-cGC"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "savetxt('/content/drive/MyDrive/y_train_other_zoomed.csv', Y_other, delimiter=',')"
      ],
      "metadata": {
        "id": "vVdmBTJ--j0p"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(Y_other)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgQ8C5ys98La",
        "outputId": "d5a1ee16-e504-4550-b48a-b9789550363c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "bVFFJghkOZLt"
      },
      "outputs": [],
      "source": [
        "#similar as done for the training data\n",
        "X_t_other=[]\n",
        "for x in X_test_other['path']:\n",
        "    for j in x:\n",
        "        for i in j:\n",
        "            for a in i :\n",
        "                X_t_other.append(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "gGtk9E_HOZL6"
      },
      "outputs": [],
      "source": [
        "X_t_other=np.asarray(X_t_other).reshape(no_of_test_other,150,150,3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/x_test_other_array_zoomed.csv', X_t_other)"
      ],
      "metadata": {
        "id": "QlEdhehc2tDL"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36aec9a0-f168-471f-f524-e939db8f8503",
        "id": "b3hcDMSWOZL6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "Y_test_other=to_categorical(y_test_other,num_classes=3)\n",
        "print(Y_test_other)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "savetxt('/content/drive/MyDrive/y_test_other_zoomed.csv', Y_test_other, delimiter=',')"
      ],
      "metadata": {
        "id": "iMFj1efP-37f"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "KeBHLzxqU6Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model=ResNet50( input_shape=(150,150,3),\n",
        "                                  include_top=False,\n",
        "                                  weights='imagenet'\n",
        "                                   )\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "     layer.trainable = False\n",
        "\n",
        "pretrained_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fzz4E6laU9mz",
        "outputId": "d58cdb6f-cdd9-481d-c170-ed597d43e585"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 156, 156, 3)          0         ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 75, 75, 64)           9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, 75, 75, 64)           256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, 75, 75, 64)           0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 77, 77, 64)           0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 38, 38, 64)           0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 38, 38, 64)           4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 38, 38, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 38, 38, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 38, 38, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 38, 38, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 38, 38, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 38, 38, 256)          16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 38, 38, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 38, 38, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, 38, 38, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, 38, 38, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, 38, 38, 256)          0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 38, 38, 64)           16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 38, 38, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 38, 38, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 38, 38, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 38, 38, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 38, 38, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 38, 38, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, 38, 38, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, 38, 38, 256)          0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, 38, 38, 256)          0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 38, 38, 64)           16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 38, 38, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 38, 38, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 38, 38, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 38, 38, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 38, 38, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 38, 38, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, 38, 38, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, 38, 38, 256)          0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, 38, 38, 256)          0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 19, 19, 128)          32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 19, 19, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 19, 19, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 19, 19, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 19, 19, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 19, 19, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 19, 19, 512)          131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 19, 19, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 19, 19, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, 19, 19, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, 19, 19, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, 19, 19, 512)          0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 19, 19, 128)          65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 19, 19, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 19, 19, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 19, 19, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 19, 19, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 19, 19, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 19, 19, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, 19, 19, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, 19, 19, 512)          0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, 19, 19, 512)          0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 19, 19, 128)          65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 19, 19, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 19, 19, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 19, 19, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 19, 19, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 19, 19, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 19, 19, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, 19, 19, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, 19, 19, 512)          0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, 19, 19, 512)          0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 19, 19, 128)          65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 19, 19, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 19, 19, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 19, 19, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 19, 19, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 19, 19, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 19, 19, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, 19, 19, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, 19, 19, 512)          0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, 19, 19, 512)          0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 10, 10, 256)          131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 10, 10, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 10, 10, 1024)         525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 10, 10, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 10, 10, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, 10, 10, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, 10, 10, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, 10, 10, 1024)         0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 10, 10, 256)          262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 10, 10, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 10, 10, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, 10, 10, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, 10, 10, 1024)         0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, 10, 10, 1024)         0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 10, 10, 256)          262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 10, 10, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 10, 10, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, 10, 10, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, 10, 10, 1024)         0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, 10, 10, 1024)         0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 10, 10, 256)          262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 10, 10, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 10, 10, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, 10, 10, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, 10, 10, 1024)         0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, 10, 10, 1024)         0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 10, 10, 256)          262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 10, 10, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 10, 10, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, 10, 10, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, 10, 10, 1024)         0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, 10, 10, 1024)         0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 10, 10, 256)          262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 10, 10, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 10, 10, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 10, 10, 256)          0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 10, 10, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, 10, 10, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, 10, 10, 1024)         0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, 10, 10, 1024)         0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 5, 5, 512)            524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 5, 5, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 5, 5, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 5, 5, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 5, 5, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 5, 5, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 5, 5, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 5, 5, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, 5, 5, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, 5, 5, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, 5, 5, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, 5, 5, 2048)           0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 5, 5, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 5, 5, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 5, 5, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 5, 5, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 5, 5, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 5, 5, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 5, 5, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, 5, 5, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, 5, 5, 2048)           0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, 5, 5, 2048)           0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 5, 5, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 5, 5, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 5, 5, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 5, 5, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 5, 5, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 5, 5, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 5, 5, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, 5, 5, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, 5, 5, 2048)           0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, 5, 5, 2048)           0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23587712 (89.98 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = pretrained_model.get_layer('conv5_block3_out')\n",
        "print('last layer of resnet : output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model_resnet = Model(pretrained_model.input, x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2VxQlKAVS7J",
        "outputId": "db6acd55-c3fa-4810-f654-8ca55a702e24"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer of resnet : output shape:  (None, 5, 5, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet.compile(optimizer = RMSprop(learning_rate=0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['acc'])"
      ],
      "metadata": {
        "id": "Zi893ViMV2dE"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_resnet.fit(X_other,Y_other,epochs=100,validation_data=(X_t_other,Y_test_other))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4F2_3A0V-Vi",
        "outputId": "75d29d02-3761-4e44-d414-2cf2d7fa7acc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 10s 145ms/step - loss: 1.4968 - acc: 0.5358 - val_loss: 1.2695 - val_acc: 0.6400\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 3s 80ms/step - loss: 0.6591 - acc: 0.7425 - val_loss: 0.5573 - val_acc: 0.7800\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.4523 - acc: 0.8267 - val_loss: 0.3176 - val_acc: 0.8933\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.3919 - acc: 0.8533 - val_loss: 0.2520 - val_acc: 0.9300\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 3s 80ms/step - loss: 0.3214 - acc: 0.8750 - val_loss: 0.6352 - val_acc: 0.7933\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.2880 - acc: 0.8942 - val_loss: 0.5874 - val_acc: 0.7067\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.3096 - acc: 0.8842 - val_loss: 0.5872 - val_acc: 0.8133\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.2394 - acc: 0.9117 - val_loss: 0.2141 - val_acc: 0.9400\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.2282 - acc: 0.9183 - val_loss: 0.2328 - val_acc: 0.9033\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.2462 - acc: 0.9000 - val_loss: 0.2158 - val_acc: 0.9400\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 3s 80ms/step - loss: 0.2056 - acc: 0.9250 - val_loss: 0.3288 - val_acc: 0.8567\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.1825 - acc: 0.9308 - val_loss: 0.2557 - val_acc: 0.9233\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.2090 - acc: 0.9200 - val_loss: 0.2894 - val_acc: 0.9100\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.1947 - acc: 0.9308 - val_loss: 0.2132 - val_acc: 0.9167\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.1827 - acc: 0.9342 - val_loss: 0.2717 - val_acc: 0.9233\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.1983 - acc: 0.9250 - val_loss: 0.2083 - val_acc: 0.9133\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.1711 - acc: 0.9400 - val_loss: 0.2202 - val_acc: 0.9100\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.1731 - acc: 0.9383 - val_loss: 0.1921 - val_acc: 0.9500\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.1473 - acc: 0.9483 - val_loss: 0.2634 - val_acc: 0.8867\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.1800 - acc: 0.9283 - val_loss: 0.1916 - val_acc: 0.9500\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.1472 - acc: 0.9450 - val_loss: 0.2016 - val_acc: 0.9433\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.1581 - acc: 0.9408 - val_loss: 0.2406 - val_acc: 0.9400\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.1405 - acc: 0.9517 - val_loss: 0.3550 - val_acc: 0.9000\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.1539 - acc: 0.9383 - val_loss: 0.3999 - val_acc: 0.8633\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.1485 - acc: 0.9492 - val_loss: 0.1880 - val_acc: 0.9500\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.1368 - acc: 0.9408 - val_loss: 0.2046 - val_acc: 0.9433\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.1600 - acc: 0.9375 - val_loss: 0.2438 - val_acc: 0.9200\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.1483 - acc: 0.9458 - val_loss: 0.2132 - val_acc: 0.9433\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.1343 - acc: 0.9517 - val_loss: 0.1819 - val_acc: 0.9500\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.1414 - acc: 0.9492 - val_loss: 0.2154 - val_acc: 0.9367\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.1333 - acc: 0.9517 - val_loss: 0.3214 - val_acc: 0.8633\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.1228 - acc: 0.9508 - val_loss: 0.1866 - val_acc: 0.9467\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 3s 80ms/step - loss: 0.1366 - acc: 0.9517 - val_loss: 0.6428 - val_acc: 0.8367\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.1417 - acc: 0.9533 - val_loss: 0.1716 - val_acc: 0.9533\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.1145 - acc: 0.9483 - val_loss: 0.2532 - val_acc: 0.9133\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.1336 - acc: 0.9517 - val_loss: 0.1659 - val_acc: 0.9500\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.1099 - acc: 0.9608 - val_loss: 0.1798 - val_acc: 0.9500\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.1189 - acc: 0.9525 - val_loss: 0.1804 - val_acc: 0.9533\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.1186 - acc: 0.9583 - val_loss: 0.3200 - val_acc: 0.9133\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.1142 - acc: 0.9508 - val_loss: 0.3218 - val_acc: 0.9000\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.1211 - acc: 0.9542 - val_loss: 0.2227 - val_acc: 0.9300\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0991 - acc: 0.9600 - val_loss: 0.1770 - val_acc: 0.9533\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.1171 - acc: 0.9575 - val_loss: 0.1903 - val_acc: 0.9400\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.1107 - acc: 0.9608 - val_loss: 0.3506 - val_acc: 0.8867\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.1011 - acc: 0.9592 - val_loss: 0.2098 - val_acc: 0.9467\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0951 - acc: 0.9642 - val_loss: 0.4150 - val_acc: 0.8667\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.1107 - acc: 0.9667 - val_loss: 0.1823 - val_acc: 0.9533\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.1066 - acc: 0.9608 - val_loss: 0.2025 - val_acc: 0.9367\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.1065 - acc: 0.9642 - val_loss: 0.1774 - val_acc: 0.9533\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.1092 - acc: 0.9600 - val_loss: 0.1653 - val_acc: 0.9533\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0981 - acc: 0.9667 - val_loss: 0.1503 - val_acc: 0.9600\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.1085 - acc: 0.9617 - val_loss: 0.1711 - val_acc: 0.9533\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.0845 - acc: 0.9725 - val_loss: 0.1990 - val_acc: 0.9500\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.1038 - acc: 0.9650 - val_loss: 0.2001 - val_acc: 0.9433\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.1007 - acc: 0.9658 - val_loss: 0.2385 - val_acc: 0.9367\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0882 - acc: 0.9675 - val_loss: 0.2703 - val_acc: 0.9300\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.0951 - acc: 0.9642 - val_loss: 0.1973 - val_acc: 0.9500\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.0922 - acc: 0.9617 - val_loss: 0.1783 - val_acc: 0.9533\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0842 - acc: 0.9608 - val_loss: 0.2167 - val_acc: 0.9400\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0913 - acc: 0.9658 - val_loss: 0.2062 - val_acc: 0.9400\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0795 - acc: 0.9692 - val_loss: 0.3690 - val_acc: 0.9067\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0969 - acc: 0.9575 - val_loss: 0.3514 - val_acc: 0.8900\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.0754 - acc: 0.9650 - val_loss: 0.1505 - val_acc: 0.9533\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0786 - acc: 0.9675 - val_loss: 0.2274 - val_acc: 0.9400\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.1002 - acc: 0.9608 - val_loss: 0.1565 - val_acc: 0.9433\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.0754 - acc: 0.9733 - val_loss: 0.2347 - val_acc: 0.9433\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0826 - acc: 0.9642 - val_loss: 0.1448 - val_acc: 0.9633\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.0740 - acc: 0.9717 - val_loss: 0.2092 - val_acc: 0.9500\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.0826 - acc: 0.9675 - val_loss: 0.2702 - val_acc: 0.9333\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0940 - acc: 0.9583 - val_loss: 0.1506 - val_acc: 0.9433\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.0919 - acc: 0.9692 - val_loss: 0.1680 - val_acc: 0.9467\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0687 - acc: 0.9717 - val_loss: 0.1880 - val_acc: 0.9533\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0968 - acc: 0.9650 - val_loss: 0.1789 - val_acc: 0.9533\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.0656 - acc: 0.9758 - val_loss: 0.1479 - val_acc: 0.9600\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.0793 - acc: 0.9717 - val_loss: 0.3224 - val_acc: 0.9233\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.0712 - acc: 0.9708 - val_loss: 0.1985 - val_acc: 0.9467\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0693 - acc: 0.9733 - val_loss: 0.1729 - val_acc: 0.9533\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.0719 - acc: 0.9725 - val_loss: 0.2123 - val_acc: 0.9500\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0701 - acc: 0.9742 - val_loss: 0.2271 - val_acc: 0.9400\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0731 - acc: 0.9725 - val_loss: 0.1963 - val_acc: 0.9400\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0610 - acc: 0.9775 - val_loss: 0.1999 - val_acc: 0.9500\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0706 - acc: 0.9725 - val_loss: 0.1763 - val_acc: 0.9533\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0743 - acc: 0.9725 - val_loss: 0.2146 - val_acc: 0.9367\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 3s 80ms/step - loss: 0.0697 - acc: 0.9742 - val_loss: 0.2135 - val_acc: 0.9500\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0649 - acc: 0.9775 - val_loss: 0.1906 - val_acc: 0.9533\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0709 - acc: 0.9750 - val_loss: 0.1753 - val_acc: 0.9533\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0751 - acc: 0.9692 - val_loss: 0.1318 - val_acc: 0.9600\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0604 - acc: 0.9775 - val_loss: 0.1282 - val_acc: 0.9600\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.0692 - acc: 0.9683 - val_loss: 0.1605 - val_acc: 0.9533\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.0643 - acc: 0.9767 - val_loss: 0.1458 - val_acc: 0.9600\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 3s 80ms/step - loss: 0.0816 - acc: 0.9683 - val_loss: 0.1680 - val_acc: 0.9533\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.0573 - acc: 0.9783 - val_loss: 0.1570 - val_acc: 0.9533\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0603 - acc: 0.9775 - val_loss: 0.1729 - val_acc: 0.9333\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.0517 - acc: 0.9825 - val_loss: 0.1562 - val_acc: 0.9533\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0624 - acc: 0.9767 - val_loss: 0.5659 - val_acc: 0.8667\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 3s 80ms/step - loss: 0.0838 - acc: 0.9667 - val_loss: 0.1648 - val_acc: 0.9533\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.0609 - acc: 0.9792 - val_loss: 0.1744 - val_acc: 0.9267\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.0608 - acc: 0.9750 - val_loss: 0.3312 - val_acc: 0.9333\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.0579 - acc: 0.9800 - val_loss: 0.3002 - val_acc: 0.9400\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.0641 - acc: 0.9750 - val_loss: 0.1358 - val_acc: 0.9533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_acc'], label = 'Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "_IhQWnoka-GL",
        "outputId": "96b40d37-8c47-4a9d-c0fe-a388df6c72cf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## InceptionV3"
      ],
      "metadata": {
        "id": "ibF5oE91J6j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_weights_file = '/content/drive/MyDrive/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "     layer.trainable = False\n",
        "\n",
        "pre_trained_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwAngwOBJG6J",
        "outputId": "21827e25-cf44-4d36-e2d4-43f21246de86"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 74, 74, 32)           864       ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 74, 74, 32)           96        ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 74, 74, 32)           0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 72, 72, 32)           9216      ['activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 72, 72, 32)           96        ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 72, 72, 32)           0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 72, 72, 64)           18432     ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 72, 72, 64)           192       ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 72, 72, 64)           0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 35, 35, 64)           0         ['activation_23[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 35, 35, 80)           5120      ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 35, 35, 80)           240       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 35, 35, 80)           0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 33, 33, 192)          138240    ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 33, 33, 192)          576       ['conv2d_35[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 33, 33, 192)          0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 16, 16, 192)          0         ['activation_25[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 16, 16, 64)           12288     ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 16, 16, 64)           192       ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 16, 16, 48)           9216      ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_29[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 16, 16, 48)           144       ['conv2d_37[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 16, 16, 96)           288       ['conv2d_40[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (None, 16, 16, 192)          0         ['max_pooling2d_9[0][0]']     \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 16, 16, 64)           12288     ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_27[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_30[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 16, 16, 32)           6144      ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 16, 16, 64)           192       ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 16, 16, 64)           192       ['conv2d_38[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 16, 16, 96)           288       ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 16, 16, 32)           96        ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 16, 16, 32)           0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_26[0][0]',       \n",
            "                                                                     'activation_28[0][0]',       \n",
            "                                                                     'activation_31[0][0]',       \n",
            "                                                                     'activation_32[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 16, 16, 64)           192       ['conv2d_46[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_36 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_36[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 16, 16, 48)           144       ['conv2d_44[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 16, 16, 96)           288       ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_37 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (Avera  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_34[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_37[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 16, 16, 64)           16384     ['average_pooling2d_1[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 16, 16, 64)           192       ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 16, 16, 64)           192       ['conv2d_45[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 16, 16, 96)           288       ['conv2d_48[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 16, 16, 64)           192       ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_38 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_39 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_33[0][0]',       \n",
            "                                                                     'activation_35[0][0]',       \n",
            "                                                                     'activation_38[0][0]',       \n",
            "                                                                     'activation_39[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 16, 16, 64)           192       ['conv2d_53[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_43[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 16, 16, 48)           144       ['conv2d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 16, 16, 96)           288       ['conv2d_54[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (Avera  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_41[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_44[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 16, 16, 64)           18432     ['average_pooling2d_2[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 16, 16, 64)           192       ['conv2d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 16, 16, 64)           192       ['conv2d_52[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 16, 16, 96)           288       ['conv2d_55[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 16, 16, 64)           192       ['conv2d_56[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_40 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_40[0][0]',       \n",
            "                                                                     'activation_42[0][0]',       \n",
            "                                                                     'activation_45[0][0]',       \n",
            "                                                                     'activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 16, 16, 64)           192       ['conv2d_58[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_48[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 16, 16, 96)           288       ['conv2d_59[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)          (None, 7, 7, 96)             82944     ['activation_49[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 7, 7, 384)            1152      ['conv2d_57[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_54 (Ba  (None, 7, 7, 96)             288       ['conv2d_60[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 7, 7, 384)            0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 7, 7, 96)             0         ['batch_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooli  (None, 7, 7, 288)            0         ['mixed2[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_47[0][0]',       \n",
            "                                                                     'activation_50[0][0]',       \n",
            "                                                                     'max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 7, 7, 128)            384       ['conv2d_65[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_55 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_55[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 7, 7, 128)            384       ['conv2d_66[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_56 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)          (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_56[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_56 (Ba  (None, 7, 7, 128)            384       ['conv2d_62[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 7, 7, 128)            384       ['conv2d_67[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_56[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_57 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_52[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_57[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_57 (Ba  (None, 7, 7, 128)            384       ['conv2d_63[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 7, 7, 128)            384       ['conv2d_68[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_58 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (Avera  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)          (None, 7, 7, 192)            172032    ['activation_53[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 7, 7, 192)            172032    ['activation_58[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_3[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_55 (Ba  (None, 7, 7, 192)            576       ['conv2d_61[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_58 (Ba  (None, 7, 7, 192)            576       ['conv2d_64[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_63 (Ba  (None, 7, 7, 192)            576       ['conv2d_69[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_64 (Ba  (None, 7, 7, 192)            576       ['conv2d_70[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_54 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_59 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_60 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_51[0][0]',       \n",
            "                                                                     'activation_54[0][0]',       \n",
            "                                                                     'activation_59[0][0]',       \n",
            "                                                                     'activation_60[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_69 (Ba  (None, 7, 7, 160)            480       ['conv2d_75[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_65 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_69[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_65[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_70 (Ba  (None, 7, 7, 160)            480       ['conv2d_76[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_66 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_70[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_66[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_66 (Ba  (None, 7, 7, 160)            480       ['conv2d_72[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_71 (Ba  (None, 7, 7, 160)            480       ['conv2d_77[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_62 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_66[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_67 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_71[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_67[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_67 (Ba  (None, 7, 7, 160)            480       ['conv2d_73[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_72 (Ba  (None, 7, 7, 160)            480       ['conv2d_78[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_63 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_67[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_68 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_72[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (Avera  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_63[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_68[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_4[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_65 (Ba  (None, 7, 7, 192)            576       ['conv2d_71[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_68 (Ba  (None, 7, 7, 192)            576       ['conv2d_74[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_73 (Ba  (None, 7, 7, 192)            576       ['conv2d_79[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_74 (Ba  (None, 7, 7, 192)            576       ['conv2d_80[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_61 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_65[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_64 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_68[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_69 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_73[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_70 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_74[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_61[0][0]',       \n",
            "                                                                     'activation_64[0][0]',       \n",
            "                                                                     'activation_69[0][0]',       \n",
            "                                                                     'activation_70[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_79 (Ba  (None, 7, 7, 160)            480       ['conv2d_85[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_75 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_79[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_75[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_80 (Ba  (None, 7, 7, 160)            480       ['conv2d_86[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_76 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_80[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_76[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_76 (Ba  (None, 7, 7, 160)            480       ['conv2d_82[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_81 (Ba  (None, 7, 7, 160)            480       ['conv2d_87[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_72 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_76[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_77 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_81[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_72[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_77[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_77 (Ba  (None, 7, 7, 160)            480       ['conv2d_83[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_82 (Ba  (None, 7, 7, 160)            480       ['conv2d_88[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_73 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_77[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_78 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_82[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (Avera  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_78[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_5[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_75 (Ba  (None, 7, 7, 192)            576       ['conv2d_81[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_78 (Ba  (None, 7, 7, 192)            576       ['conv2d_84[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_83 (Ba  (None, 7, 7, 192)            576       ['conv2d_89[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_84 (Ba  (None, 7, 7, 192)            576       ['conv2d_90[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_71 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_75[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_74 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_78[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_79 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_83[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_80 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_84[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_71[0][0]',       \n",
            "                                                                     'activation_74[0][0]',       \n",
            "                                                                     'activation_79[0][0]',       \n",
            "                                                                     'activation_80[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_89 (Ba  (None, 7, 7, 192)            576       ['conv2d_95[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_85 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_89[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_85[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_90 (Ba  (None, 7, 7, 192)            576       ['conv2d_96[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_86 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_90[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_86[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_86 (Ba  (None, 7, 7, 192)            576       ['conv2d_92[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_91 (Ba  (None, 7, 7, 192)            576       ['conv2d_97[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_82 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_86[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_87 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_91[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_82[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_87[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_87 (Ba  (None, 7, 7, 192)            576       ['conv2d_93[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_92 (Ba  (None, 7, 7, 192)            576       ['conv2d_98[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_83 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_87[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_88 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_92[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (Avera  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_83[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_88[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_6[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_85 (Ba  (None, 7, 7, 192)            576       ['conv2d_91[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_88 (Ba  (None, 7, 7, 192)            576       ['conv2d_94[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_93 (Ba  (None, 7, 7, 192)            576       ['conv2d_99[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_94 (Ba  (None, 7, 7, 192)            576       ['conv2d_100[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_81 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_85[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_84 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_88[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_89 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_93[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_90 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_94[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_81[0][0]',       \n",
            "                                                                     'activation_84[0][0]',       \n",
            "                                                                     'activation_89[0][0]',       \n",
            "                                                                     'activation_90[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_97 (Ba  (None, 7, 7, 192)            576       ['conv2d_103[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_93 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_97[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_93[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_98 (Ba  (None, 7, 7, 192)            576       ['conv2d_104[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_94 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_98[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_94[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_95 (Ba  (None, 7, 7, 192)            576       ['conv2d_101[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_99 (Ba  (None, 7, 7, 192)            576       ['conv2d_105[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_91 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_95[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_95 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_99[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)         (None, 3, 3, 320)            552960    ['activation_91[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)         (None, 3, 3, 192)            331776    ['activation_95[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_96 (Ba  (None, 3, 3, 320)            960       ['conv2d_102[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_100 (B  (None, 3, 3, 192)            576       ['conv2d_106[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_92 (Activation)  (None, 3, 3, 320)            0         ['batch_normalization_96[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_96 (Activation)  (None, 3, 3, 192)            0         ['batch_normalization_100[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 3, 3, 768)            0         ['mixed7[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)        (None, 3, 3, 1280)           0         ['activation_92[0][0]',       \n",
            "                                                                     'activation_96[0][0]',       \n",
            "                                                                     'max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)         (None, 3, 3, 448)            573440    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_105 (B  (None, 3, 3, 448)            1344      ['conv2d_111[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_101 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_105[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)         (None, 3, 3, 384)            491520    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_101[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_102 (B  (None, 3, 3, 384)            1152      ['conv2d_108[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_106 (B  (None, 3, 3, 384)            1152      ['conv2d_112[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_98 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_102[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_102 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_106[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_98[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_98[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_102[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_102[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (Avera  (None, 3, 3, 1280)           0         ['mixed8[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)         (None, 3, 3, 320)            409600    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_103 (B  (None, 3, 3, 384)            1152      ['conv2d_109[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_104 (B  (None, 3, 3, 384)            1152      ['conv2d_110[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_107 (B  (None, 3, 3, 384)            1152      ['conv2d_113[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_108 (B  (None, 3, 3, 384)            1152      ['conv2d_114[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)         (None, 3, 3, 192)            245760    ['average_pooling2d_7[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_101 (B  (None, 3, 3, 320)            960       ['conv2d_107[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_99 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_103[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_100 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_104[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_103 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_107[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_104 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_108[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_109 (B  (None, 3, 3, 192)            576       ['conv2d_115[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_97 (Activation)  (None, 3, 3, 320)            0         ['batch_normalization_101[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)      (None, 3, 3, 768)            0         ['activation_99[0][0]',       \n",
            "                                                                     'activation_100[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenat  (None, 3, 3, 768)            0         ['activation_103[0][0]',      \n",
            " e)                                                                  'activation_104[0][0]']      \n",
            "                                                                                                  \n",
            " activation_105 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_109[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)        (None, 3, 3, 2048)           0         ['activation_97[0][0]',       \n",
            "                                                                     'mixed9_0[0][0]',            \n",
            "                                                                     'concatenate_16[0][0]',      \n",
            "                                                                     'activation_105[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)         (None, 3, 3, 448)            917504    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_114 (B  (None, 3, 3, 448)            1344      ['conv2d_120[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_110 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_114[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)         (None, 3, 3, 384)            786432    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_110[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_111 (B  (None, 3, 3, 384)            1152      ['conv2d_117[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_115 (B  (None, 3, 3, 384)            1152      ['conv2d_121[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_107 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_111[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_111 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_115[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_107[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_107[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_111[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_111[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (Avera  (None, 3, 3, 2048)           0         ['mixed9[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)         (None, 3, 3, 320)            655360    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_112 (B  (None, 3, 3, 384)            1152      ['conv2d_118[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_113 (B  (None, 3, 3, 384)            1152      ['conv2d_119[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_116 (B  (None, 3, 3, 384)            1152      ['conv2d_122[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_117 (B  (None, 3, 3, 384)            1152      ['conv2d_123[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)         (None, 3, 3, 192)            393216    ['average_pooling2d_8[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_110 (B  (None, 3, 3, 320)            960       ['conv2d_116[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_108 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_112[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_109 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_113[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_112 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_116[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_113 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_117[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_118 (B  (None, 3, 3, 192)            576       ['conv2d_124[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_106 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_110[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)      (None, 3, 3, 768)            0         ['activation_108[0][0]',      \n",
            "                                                                     'activation_109[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenat  (None, 3, 3, 768)            0         ['activation_112[0][0]',      \n",
            " e)                                                                  'activation_113[0][0]']      \n",
            "                                                                                                  \n",
            " activation_114 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_118[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)       (None, 3, 3, 2048)           0         ['activation_106[0][0]',      \n",
            "                                                                     'mixed9_1[0][0]',            \n",
            "                                                                     'concatenate_17[0][0]',      \n",
            "                                                                     'activation_114[0][0]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21802784 (83.17 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 21802784 (83.17 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer of vgg output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model_inception = Model(pre_trained_model.input, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSDDLyqkblDP",
        "outputId": "e6996fb7-22f5-445a-d315-d84d626c6dd6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer of vgg output shape:  (None, 7, 7, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_inception.compile(optimizer = RMSprop(learning_rate=0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['acc'])\n"
      ],
      "metadata": {
        "id": "whc7xywsbpxr"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_inception.fit(X_other,Y_other,epochs=100,validation_data=(X_t_other,Y_test_other))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z1gVhztb3eo",
        "outputId": "f81252ba-e985-4f8d-e39f-5777e30b9f5b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 12s 146ms/step - loss: 0.5099 - acc: 0.9033 - val_loss: 0.0944 - val_acc: 0.9800\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.0763 - acc: 0.9742 - val_loss: 0.1866 - val_acc: 0.9667\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 0.0388 - acc: 0.9875 - val_loss: 0.5371 - val_acc: 0.9300\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 0.0202 - acc: 0.9958 - val_loss: 0.1060 - val_acc: 0.9800\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 0.0381 - acc: 0.9900 - val_loss: 0.0934 - val_acc: 0.9800\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 0.0126 - acc: 0.9942 - val_loss: 0.1465 - val_acc: 0.9767\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 0.9833\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 6.6462e-04 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 0.9833\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 4.7619e-04 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9833\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 3.3737e-04 - acc: 1.0000 - val_loss: 0.0996 - val_acc: 0.9833\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 1.9263e-04 - acc: 1.0000 - val_loss: 0.0893 - val_acc: 0.9833\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.6616e-04 - acc: 1.0000 - val_loss: 0.0991 - val_acc: 0.9833\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 1.6254e-04 - acc: 1.0000 - val_loss: 0.0968 - val_acc: 0.9833\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.2937e-04 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9833\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.0789e-04 - acc: 1.0000 - val_loss: 0.1039 - val_acc: 0.9833\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 2s 45ms/step - loss: 1.5614e-04 - acc: 1.0000 - val_loss: 0.0996 - val_acc: 0.9833\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 2s 45ms/step - loss: 1.0632e-04 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 0.9833\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 9.8690e-05 - acc: 1.0000 - val_loss: 0.1024 - val_acc: 0.9833\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 9.4538e-05 - acc: 1.0000 - val_loss: 0.1011 - val_acc: 0.9833\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 9.5810e-05 - acc: 1.0000 - val_loss: 0.1046 - val_acc: 0.9833\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 8.4671e-05 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9833\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.2624e-04 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9833\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 8.5689e-05 - acc: 1.0000 - val_loss: 0.1013 - val_acc: 0.9833\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 7.1566e-05 - acc: 1.0000 - val_loss: 0.0975 - val_acc: 0.9833\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 5.8902e-05 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9833\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 8.1786e-05 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9833\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 6.2020e-05 - acc: 1.0000 - val_loss: 0.1090 - val_acc: 0.9833\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 6.6601e-05 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9833\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 7.0840e-05 - acc: 1.0000 - val_loss: 0.0970 - val_acc: 0.9833\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 5.2007e-05 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9833\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 4.5629e-05 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 0.9833\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 6.6539e-05 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9833\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 6.2594e-05 - acc: 1.0000 - val_loss: 0.1003 - val_acc: 0.9833\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 4.7763e-05 - acc: 1.0000 - val_loss: 0.1039 - val_acc: 0.9833\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 4.6736e-05 - acc: 1.0000 - val_loss: 0.1049 - val_acc: 0.9833\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 3.4914e-05 - acc: 1.0000 - val_loss: 0.1068 - val_acc: 0.9833\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 3.2510e-05 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9833\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 3.8849e-05 - acc: 1.0000 - val_loss: 0.1090 - val_acc: 0.9833\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 3.0326e-05 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9833\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 3.9733e-05 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9833\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 3.2925e-05 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9833\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 2s 41ms/step - loss: 3.5113e-05 - acc: 1.0000 - val_loss: 0.1027 - val_acc: 0.9833\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 3.5308e-05 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 0.9833\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 4.1218e-05 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 0.9833\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 3.4091e-05 - acc: 1.0000 - val_loss: 0.1041 - val_acc: 0.9833\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 2.4758e-05 - acc: 1.0000 - val_loss: 0.1046 - val_acc: 0.9833\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 2.8497e-05 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9833\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 3.6516e-05 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9833\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 3.1020e-05 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9833\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 2.5386e-05 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9833\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 3.3213e-05 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9833\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 3.1831e-05 - acc: 1.0000 - val_loss: 0.1110 - val_acc: 0.9833\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 2.5125e-05 - acc: 1.0000 - val_loss: 0.1123 - val_acc: 0.9833\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 2.5080e-05 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9833\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 2.5110e-05 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9833\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 2.4389e-05 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9833\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 2.6127e-05 - acc: 1.0000 - val_loss: 0.1075 - val_acc: 0.9833\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 3.0129e-05 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.9833\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 2.1580e-05 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9833\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 2.0817e-05 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9833\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 1.8761e-05 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9833\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 2s 45ms/step - loss: 2.0170e-05 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9833\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 2.4361e-05 - acc: 1.0000 - val_loss: 0.1147 - val_acc: 0.9833\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 2.3985e-05 - acc: 1.0000 - val_loss: 0.1122 - val_acc: 0.9833\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 2s 45ms/step - loss: 2.1129e-05 - acc: 1.0000 - val_loss: 0.1123 - val_acc: 0.9833\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 2.1419e-05 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9833\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 2.0942e-05 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9833\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 2.0964e-05 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9833\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 1.7386e-05 - acc: 1.0000 - val_loss: 0.1129 - val_acc: 0.9833\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 2.2293e-05 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 0.9833\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 1.5883e-05 - acc: 1.0000 - val_loss: 0.1138 - val_acc: 0.9833\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 2.0082e-05 - acc: 1.0000 - val_loss: 0.1136 - val_acc: 0.9833\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 2.5353e-05 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9833\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 2.2042e-05 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 0.9833\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 2.1008e-05 - acc: 1.0000 - val_loss: 0.1065 - val_acc: 0.9833\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 1.7636e-05 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9833\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 1.3905e-05 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9833\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 2s 45ms/step - loss: 1.5537e-05 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 0.9833\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.3990e-05 - acc: 1.0000 - val_loss: 0.1136 - val_acc: 0.9833\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.4512e-05 - acc: 1.0000 - val_loss: 0.1136 - val_acc: 0.9833\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.6949e-05 - acc: 1.0000 - val_loss: 0.1141 - val_acc: 0.9833\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 2s 45ms/step - loss: 2.2631e-05 - acc: 1.0000 - val_loss: 0.1136 - val_acc: 0.9833\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 1.6287e-05 - acc: 1.0000 - val_loss: 0.1130 - val_acc: 0.9833\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 2s 45ms/step - loss: 1.5605e-05 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9833\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 1.7312e-05 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 0.9833\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 1.6528e-05 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9833\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 1.7634e-05 - acc: 1.0000 - val_loss: 0.1149 - val_acc: 0.9833\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.3479e-05 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9833\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 1.6311e-05 - acc: 1.0000 - val_loss: 0.1139 - val_acc: 0.9833\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.5506e-05 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 0.9833\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 2.1863e-05 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9833\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 1.4400e-05 - acc: 1.0000 - val_loss: 0.1132 - val_acc: 0.9833\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.1696e-05 - acc: 1.0000 - val_loss: 0.1131 - val_acc: 0.9833\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 1.4284e-05 - acc: 1.0000 - val_loss: 0.1141 - val_acc: 0.9833\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 1.1899e-05 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9833\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 1.6505e-05 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9833\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 1.2010e-05 - acc: 1.0000 - val_loss: 0.1151 - val_acc: 0.9833\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 1.3544e-05 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9833\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 1.7934e-05 - acc: 1.0000 - val_loss: 0.1180 - val_acc: 0.9833\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 1.4545e-05 - acc: 1.0000 - val_loss: 0.1146 - val_acc: 0.9833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_acc'], label = 'Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "fMtq7IJqjG7g",
        "outputId": "b16d04cf-bd06-4336-c32f-0f19c7bc2843"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the saved train and test files"
      ],
      "metadata": {
        "id": "zUBu4AsH2ts1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_other_loaded = pd.read_csv('/content/drive/MyDrive/x_train_other.csv')\n",
        "X_test_other_loaded = pd.read_csv('/content/drive/MyDrive/x_test_other.csv')\n",
        "Y_other_loaded = loadtxt('/content/drive/MyDrive/y_train_other_resnet.csv', delimiter=',')\n",
        "Y_test_other_loaded = loadtxt('/content/drive/MyDrive/y_test_other_resnet.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "JDfnScmg3sA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16"
      ],
      "metadata": {
        "id": "0DjWYfUZckoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file='/content/drive/MyDrive/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pretrained_model=VGG16(input_shape = (150, 150, 3),\n",
        "                        include_top = False,\n",
        "                        weights =None)\n",
        "\n",
        "pretrained_model.load_weights(file)\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "     layer.trainable = False"
      ],
      "metadata": {
        "id": "ij6iFRNucs8b"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = pretrained_model.get_layer('block5_pool')\n",
        "print('last layer of vgg : output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model_vgg = Model(pretrained_model.input, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pn-Brjqc7lu",
        "outputId": "4b78565b-cb8e-40a6-e9e7-5ac2afae792f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer of vgg : output shape:  (None, 4, 4, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_vgg.compile(optimizer = RMSprop(learning_rate=0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['acc'])"
      ],
      "metadata": {
        "id": "38dDnDGUdBTA"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_vgg.fit(X_other,Y_other,epochs=100,validation_data=(X_t_other,Y_test_other))\n"
      ],
      "metadata": {
        "id": "gP4maliodJzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82131eed-acf0-49c8-bada-e217dde77cd6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 9s 178ms/step - loss: 0.2383 - acc: 0.9142 - val_loss: 0.1666 - val_acc: 0.9367\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 4s 103ms/step - loss: 0.0594 - acc: 0.9817 - val_loss: 0.1084 - val_acc: 0.9633\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0308 - acc: 0.9925 - val_loss: 0.0584 - val_acc: 0.9867\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0163 - acc: 0.9967 - val_loss: 0.0811 - val_acc: 0.9733\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.0148 - acc: 0.9967 - val_loss: 0.0627 - val_acc: 0.9800\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0147 - acc: 0.9967 - val_loss: 0.0617 - val_acc: 0.9833\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.0586 - val_acc: 0.9867\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 0.0508 - val_acc: 0.9867\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0081 - acc: 0.9983 - val_loss: 0.0549 - val_acc: 0.9900\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9767\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 4s 103ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0628 - val_acc: 0.9867\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0581 - val_acc: 0.9867\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0616 - val_acc: 0.9867\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 0.9867\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9867\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0687 - val_acc: 0.9833\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 0.9867\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 4s 104ms/step - loss: 8.6020e-04 - acc: 1.0000 - val_loss: 0.0761 - val_acc: 0.9767\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0791 - val_acc: 0.9900\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 6.9090e-04 - acc: 1.0000 - val_loss: 0.0788 - val_acc: 0.9867\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 7.1728e-04 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 0.9867\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 4.1943e-04 - acc: 1.0000 - val_loss: 0.0725 - val_acc: 0.9867\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 5.0333e-04 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9867\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 5.4324e-04 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 0.9900\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 3.0770e-04 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 0.9867\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 3.5890e-04 - acc: 1.0000 - val_loss: 0.0613 - val_acc: 0.9900\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 3.5678e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9867\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 3.3034e-04 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9900\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 4s 109ms/step - loss: 3.2240e-04 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 0.9867\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 3.7287e-04 - acc: 1.0000 - val_loss: 0.0755 - val_acc: 0.9900\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 3.1724e-04 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9867\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 2.2955e-04 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9867\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 4s 109ms/step - loss: 3.9414e-04 - acc: 1.0000 - val_loss: 0.0743 - val_acc: 0.9867\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 2.2395e-04 - acc: 1.0000 - val_loss: 0.0744 - val_acc: 0.9867\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.9636e-04 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9867\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 1.8287e-04 - acc: 1.0000 - val_loss: 0.0823 - val_acc: 0.9900\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 1.9143e-04 - acc: 1.0000 - val_loss: 0.0759 - val_acc: 0.9867\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 2.4383e-04 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 0.9867\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 1.4176e-04 - acc: 1.0000 - val_loss: 0.0791 - val_acc: 0.9867\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.6490e-04 - acc: 1.0000 - val_loss: 0.0731 - val_acc: 0.9867\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.6989e-04 - acc: 1.0000 - val_loss: 0.0743 - val_acc: 0.9867\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 3s 91ms/step - loss: 1.6890e-04 - acc: 1.0000 - val_loss: 0.0733 - val_acc: 0.9867\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.5821e-04 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9867\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 1.2918e-04 - acc: 1.0000 - val_loss: 0.0788 - val_acc: 0.9867\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.5619e-04 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 0.9867\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 1.3127e-04 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 0.9867\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 1.0692e-04 - acc: 1.0000 - val_loss: 0.0782 - val_acc: 0.9867\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.2646e-04 - acc: 1.0000 - val_loss: 0.0837 - val_acc: 0.9900\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.3433e-04 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 0.9867\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.0367e-04 - acc: 1.0000 - val_loss: 0.0738 - val_acc: 0.9867\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 1.1684e-04 - acc: 1.0000 - val_loss: 0.0788 - val_acc: 0.9867\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 9.4926e-05 - acc: 1.0000 - val_loss: 0.0819 - val_acc: 0.9900\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 1.1685e-04 - acc: 1.0000 - val_loss: 0.0862 - val_acc: 0.9900\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.0920e-04 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 0.9867\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 9.7460e-05 - acc: 1.0000 - val_loss: 0.0746 - val_acc: 0.9867\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 7.6850e-05 - acc: 1.0000 - val_loss: 0.0781 - val_acc: 0.9867\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 9.8610e-05 - acc: 1.0000 - val_loss: 0.0812 - val_acc: 0.9867\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 1.0679e-04 - acc: 1.0000 - val_loss: 0.0885 - val_acc: 0.9900\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 9.5199e-05 - acc: 1.0000 - val_loss: 0.0803 - val_acc: 0.9867\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 8.2345e-05 - acc: 1.0000 - val_loss: 0.0786 - val_acc: 0.9867\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 9.4484e-05 - acc: 1.0000 - val_loss: 0.0803 - val_acc: 0.9867\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 8.5337e-05 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 0.9867\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 6.9551e-05 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9867\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 8.6053e-05 - acc: 1.0000 - val_loss: 0.0792 - val_acc: 0.9867\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 9.8438e-05 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 0.9867\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 8.6510e-05 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 0.9867\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 8.7908e-05 - acc: 1.0000 - val_loss: 0.0803 - val_acc: 0.9867\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 7.2212e-05 - acc: 1.0000 - val_loss: 0.0805 - val_acc: 0.9867\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 7.1789e-05 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9867\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 7.8845e-05 - acc: 1.0000 - val_loss: 0.0807 - val_acc: 0.9867\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 8.1291e-05 - acc: 1.0000 - val_loss: 0.0845 - val_acc: 0.9900\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 7.7387e-05 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9867\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 7.1472e-05 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9867\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 8.9217e-05 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 0.9867\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 7.3266e-05 - acc: 1.0000 - val_loss: 0.0775 - val_acc: 0.9867\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 6.6499e-05 - acc: 1.0000 - val_loss: 0.0814 - val_acc: 0.9867\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 6.3829e-05 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9900\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 6.2510e-05 - acc: 1.0000 - val_loss: 0.0790 - val_acc: 0.9867\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 6.7181e-05 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 0.9900\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 5.6658e-05 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9867\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 4.8992e-05 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 0.9900\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 4.9465e-05 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 0.9867\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 3s 91ms/step - loss: 5.4868e-05 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 0.9867\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 5.7568e-05 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9867\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 6.1827e-05 - acc: 1.0000 - val_loss: 0.0802 - val_acc: 0.9867\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 6.1251e-05 - acc: 1.0000 - val_loss: 0.0832 - val_acc: 0.9867\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 7.1313e-05 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9867\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 5.2051e-05 - acc: 1.0000 - val_loss: 0.0825 - val_acc: 0.9867\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 4.9315e-05 - acc: 1.0000 - val_loss: 0.0824 - val_acc: 0.9867\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 5.0706e-05 - acc: 1.0000 - val_loss: 0.0832 - val_acc: 0.9867\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 5.0156e-05 - acc: 1.0000 - val_loss: 0.0853 - val_acc: 0.9867\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 6.0577e-05 - acc: 1.0000 - val_loss: 0.0812 - val_acc: 0.9867\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 4.5026e-05 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 0.9867\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 3.6237e-05 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 0.9867\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 4.5540e-05 - acc: 1.0000 - val_loss: 0.0835 - val_acc: 0.9867\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 5.5090e-05 - acc: 1.0000 - val_loss: 0.0814 - val_acc: 0.9867\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 4.8914e-05 - acc: 1.0000 - val_loss: 0.0853 - val_acc: 0.9867\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 4.8684e-05 - acc: 1.0000 - val_loss: 0.0832 - val_acc: 0.9867\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 5.2062e-05 - acc: 1.0000 - val_loss: 0.0824 - val_acc: 0.9867\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 3s 92ms/step - loss: 4.2920e-05 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 0.9867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_acc'], label = 'Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "26vC0VhUoDxU",
        "outputId": "b90c14b6-3bc3-4292-c22f-499736c084d8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying the Deep Neural Networks and Transfer Learning for Food Crop Identification in UAV Images\n",
        "by Robert Chew 1,*ORCID,Jay Rineer 1,Robert Beach 1ORCID,Maggie O’Neil 1,Noel Ujeneza 2,Daniel Lapidus 1,Thomas Miano 1,Meghan Hegarty-Craver 1,Jason Polly 3 andDorota S. Temple 1\n",
        "\n",
        "## Using VGG16 with Imagenet weights and Adam optimizer"
      ],
      "metadata": {
        "id": "-slDTLA69VFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "mT0Tu0aLBH6g"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model=VGG16(input_shape = (150, 150, 3),\n",
        "                        include_top=False,\n",
        "                                  weights='imagenet')\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "     layer.trainable = False\n",
        "\n",
        "pretrained_model.summary()\n",
        "\n",
        "\n",
        "# Create a new model for feature extraction\n",
        "feature_extractor = Model(inputs=pretrained_model.input, outputs=pretrained_model.output)\n",
        "\n",
        "# Build the classification model\n",
        "model_vgg_imagenet = Sequential()\n",
        "model_vgg_imagenet.add(feature_extractor)\n",
        "model_vgg_imagenet.add(Flatten())\n",
        "model_vgg_imagenet.add(Dense(256, activation='relu'))\n",
        "model_vgg_imagenet.add(Dropout(0.5))\n",
        "model_vgg_imagenet.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_vgg_imagenet.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CQR817591ko",
        "outputId": "688e940f-d81c-412c-8be2-9bcf2905cab2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_vgg_imagenet.fit(X_other,Y_other,epochs=100,validation_data=(X_t_other,Y_test_other))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqAs3kKFBTuw",
        "outputId": "86024759-7d38-4626-958e-bc31dd35c9fe"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 5s 105ms/step - loss: 0.3083 - accuracy: 0.9025 - val_loss: 0.1067 - val_accuracy: 0.9733\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0592 - accuracy: 0.9800 - val_loss: 0.0731 - val_accuracy: 0.9733\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.0818 - val_accuracy: 0.9733\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 0.0447 - val_accuracy: 0.9867\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.0178 - accuracy: 0.9958 - val_loss: 0.0652 - val_accuracy: 0.9867\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.0661 - val_accuracy: 0.9867\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0083 - accuracy: 0.9950 - val_loss: 0.0697 - val_accuracy: 0.9867\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9867\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9867\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0768 - val_accuracy: 0.9867\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9867\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9867\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9900\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9833\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9833\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 4s 104ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0684 - val_accuracy: 0.9867\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0747 - val_accuracy: 0.9867\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9867\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9867\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 7.6590e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9867\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9800\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9833\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 4.9943e-04 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9867\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 3.8059e-04 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9833\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 3.8440e-04 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9867\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 4.8165e-04 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9867\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 4s 104ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0695 - val_accuracy: 0.9800\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9867\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 3.6046e-04 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9833\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 3.1277e-04 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9833\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 3.8363e-04 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9867\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 3.9114e-04 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9867\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 1.3875e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9867\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 2.5421e-04 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9833\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 3s 93ms/step - loss: 2.1977e-04 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9867\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.3871e-04 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9867\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.5429e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9867\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 1.7832e-04 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9900\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 7.8897e-05 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9867\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.4290e-04 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9867\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9867\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9900\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 0.0978 - val_accuracy: 0.9867\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 0.0766 - accuracy: 0.9833 - val_loss: 0.2084 - val_accuracy: 0.9700\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0924 - accuracy: 0.9775 - val_loss: 0.0988 - val_accuracy: 0.9833\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.1233 - val_accuracy: 0.9833\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 0.0319 - accuracy: 0.9933 - val_loss: 0.0958 - val_accuracy: 0.9767\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 0.0124 - accuracy: 0.9950 - val_loss: 0.1080 - val_accuracy: 0.9833\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0064 - accuracy: 0.9967 - val_loss: 0.0896 - val_accuracy: 0.9867\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 4s 104ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0935 - val_accuracy: 0.9867\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9833\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0979 - val_accuracy: 0.9900\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 4s 104ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0857 - val_accuracy: 0.9900\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 3.4049e-04 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9900\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 8.7749e-04 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9867\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 9.7713e-04 - accuracy: 0.9992 - val_loss: 0.1038 - val_accuracy: 0.9867\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9900\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9900\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 3.1909e-04 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9900\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 1.8137e-04 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9867\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.2994e-04 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9867\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 3.7917e-04 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9867\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1109 - val_accuracy: 0.9900\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9867\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 4s 104ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.1080 - val_accuracy: 0.9900\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 9.0306e-04 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9867\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 7.2489e-04 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9833\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.1183 - val_accuracy: 0.9900\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9800\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 0.0991 - val_accuracy: 0.9900\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 0.0062 - accuracy: 0.9967 - val_loss: 0.0968 - val_accuracy: 0.9867\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 8.4074e-04 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9867\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1201 - val_accuracy: 0.9833\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 0.0072 - accuracy: 0.9958 - val_loss: 0.1432 - val_accuracy: 0.9867\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.1275 - val_accuracy: 0.9833\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0785 - val_accuracy: 0.9900\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 7.8150e-04 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9900\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 8.4434e-04 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9867\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 6.4151e-04 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9833\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 3s 92ms/step - loss: 4.8120e-04 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9833\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 2.3754e-04 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9867\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 3.4176e-04 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9867\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 7.0243e-05 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9867\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 2.3943e-04 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9833\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.7765e-04 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9833\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 7.2745e-05 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9833\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 9.3903e-05 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9833\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 1.2424e-04 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9867\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 4.8417e-05 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9867\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 8.0756e-05 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9867\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 5.9725e-05 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9867\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 4s 104ms/step - loss: 6.5294e-05 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9867\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 9.1614e-05 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9867\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.8257e-04 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9900\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 1.9950e-04 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9867\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 5.1444e-05 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9867\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 6.6348e-05 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9867\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 5.5263e-05 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9867\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 0.0847 - val_accuracy: 0.9867\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.0039 - accuracy: 0.9975 - val_loss: 0.1244 - val_accuracy: 0.9867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "CX4saaLpDPEq",
        "outputId": "8a59d2c0-6ef1-4caf-c04d-0d9700d55372"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16 on unzoomed dataset"
      ],
      "metadata": {
        "id": "TvTS4MRHFVCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "data_unzoomed = pd.read_csv('/content/drive/MyDrive/training_details_500.csv')\n",
        "\n",
        "\n",
        "data_unzoomed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "YEb1L6c3FlLE",
        "outputId": "f8008283-ede0-4a14-fb9c-8e7f970d780e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                path  label      crop\n",
              "0     /content/drive/MyDrive/Cotton/aug-DJI_0557.JPG      1    cotton\n",
              "1     /content/drive/MyDrive/Cotton/aug-DJI_0558.JPG      1    cotton\n",
              "2     /content/drive/MyDrive/Cotton/aug-DJI_0559.JPG      1    cotton\n",
              "3     /content/drive/MyDrive/Cotton/aug-DJI_0560.JPG      1    cotton\n",
              "4     /content/drive/MyDrive/Cotton/aug-DJI_0561.JPG      1    cotton\n",
              "...                                              ...    ...       ...\n",
              "1495     /content/drive/MyDrive/RedGram/DJI_0151.JPG      0  red gram\n",
              "1496     /content/drive/MyDrive/RedGram/DJI_0149.JPG      0  red gram\n",
              "1497     /content/drive/MyDrive/RedGram/DJI_0148.JPG      0  red gram\n",
              "1498     /content/drive/MyDrive/RedGram/DJI_0147.JPG      0  red gram\n",
              "1499     /content/drive/MyDrive/RedGram/DJI_0146.JPG      0  red gram\n",
              "\n",
              "[1500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d9009de-c600-4497-9d9e-f4a83ca20e3a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>crop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Cotton/aug-DJI_0557.JPG</td>\n",
              "      <td>1</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Cotton/aug-DJI_0558.JPG</td>\n",
              "      <td>1</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Cotton/aug-DJI_0559.JPG</td>\n",
              "      <td>1</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Cotton/aug-DJI_0560.JPG</td>\n",
              "      <td>1</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Cotton/aug-DJI_0561.JPG</td>\n",
              "      <td>1</td>\n",
              "      <td>cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>/content/drive/MyDrive/RedGram/DJI_0151.JPG</td>\n",
              "      <td>0</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>/content/drive/MyDrive/RedGram/DJI_0149.JPG</td>\n",
              "      <td>0</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>/content/drive/MyDrive/RedGram/DJI_0148.JPG</td>\n",
              "      <td>0</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>/content/drive/MyDrive/RedGram/DJI_0147.JPG</td>\n",
              "      <td>0</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>/content/drive/MyDrive/RedGram/DJI_0146.JPG</td>\n",
              "      <td>0</td>\n",
              "      <td>red gram</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d9009de-c600-4497-9d9e-f4a83ca20e3a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d9009de-c600-4497-9d9e-f4a83ca20e3a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d9009de-c600-4497-9d9e-f4a83ca20e3a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-314d4b6c-d204-4d79-92f2-7f18e4c68460\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-314d4b6c-d204-4d79-92f2-7f18e4c68460')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-314d4b6c-d204-4d79-92f2-7f18e4c68460 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file='/content/drive/MyDrive/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pretrained_model=VGG16(input_shape = (150, 150, 3),\n",
        "                        include_top = False,\n",
        "                        weights =None)\n",
        "\n",
        "pretrained_model.load_weights(file)\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "     layer.trainable = False"
      ],
      "metadata": {
        "id": "JRS0TPzZFNpz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = pretrained_model.get_layer('block5_pool')\n",
        "print('last layer of vgg : output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model_vgg = Model(pretrained_model.input, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9zo3M3sFaHy",
        "outputId": "ebc7a65e-6842-4439-cc2c-0b411fe0c83b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer of vgg : output shape:  (None, 4, 4, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "N8Ost6CXGPXV"
      },
      "outputs": [],
      "source": [
        "def path_to_RGB_other(path :str):\n",
        "   path=path.replace('/input','/input/agriculture-crop-images/crop_images')\n",
        "   img = Image.open(path)\n",
        "   img = img.resize((150, 150))\n",
        "   img_arr = np.array(img)\n",
        "   img_arr = img_arr.reshape(150,150,3)\n",
        "\n",
        "   return img_arr\n",
        "\n",
        "def path_to_RGB_test_other(path :str):\n",
        "   img = Image.open(path)\n",
        "   img = img.resize((150, 150))\n",
        "   img_arr = np.array(img)\n",
        "   img_arr = img_arr.reshape(150,150,3)\n",
        "   return img_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "kO3s7w4IGPXd"
      },
      "outputs": [],
      "source": [
        "X_train_unzoomed, X_test_unzoomed, y_train_unzoomed, y_test_unzoomed = train_test_split(data_unzoomed.drop(columns=['label']), data_unzoomed['label'] , test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "ORiPWXlsGPXd"
      },
      "outputs": [],
      "source": [
        "X_train_unzoomed['path']=X_train_unzoomed['path'].apply(path_to_RGB_other)\n",
        "X_test_unzoomed['path']=X_test_unzoomed['path'].apply(path_to_RGB_test_other)\n",
        "X_train_unzoomed['path']=X_train_unzoomed['path']/255\n",
        "X_test_unzoomed['path']=X_test_unzoomed['path']/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "oLuaHFCdOLFU"
      },
      "outputs": [],
      "source": [
        "no_of_train_unzoomed = X_train_unzoomed['path'].shape[0]\n",
        "no_of_test_unzoomed = X_test_unzoomed['path'].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "XIr2cB6jOLFV"
      },
      "outputs": [],
      "source": [
        "X_unzoomed=[]\n",
        "for x in X_train_unzoomed['path']:\n",
        "    for j in x:\n",
        "        for i in j:\n",
        "            for a in i :\n",
        "                X_unzoomed.append(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "9DtyV0nhOLFV"
      },
      "outputs": [],
      "source": [
        "X_unzoomed=np.asarray(X_unzoomed).reshape(no_of_train_other,150,150,3)\n",
        "Y_unzoomed=y_train_unzoomed\n",
        "Y_unzoomed=to_categorical(Y_unzoomed,num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save numpy array as csv file\n",
        "from numpy import asarray\n",
        "from numpy import savetxt, loadtxt"
      ],
      "metadata": {
        "id": "X3cV_UlzSdty"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "W-SuqytqSk1i"
      },
      "outputs": [],
      "source": [
        "savetxt('/content/drive/MyDrive/y_train_unzoomed.csv', Y_unzoomed, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/x_train_array_unzoomed.csv', X_unzoomed)"
      ],
      "metadata": {
        "id": "yJD7x9cRnbFW"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16573fc4-12f5-4b21-aaee-d428e453bcf6",
        "id": "L_ncIo_OSk1r"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "type(Y_other)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "VVWG7RTuSk1r"
      },
      "outputs": [],
      "source": [
        "#similar as done for the training data\n",
        "X_t_unzoomed=[]\n",
        "for x in X_test_unzoomed['path']:\n",
        "    for j in x:\n",
        "        for i in j:\n",
        "            for a in i :\n",
        "                X_t_unzoomed.append(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "nKJKDVj6Sk1r"
      },
      "outputs": [],
      "source": [
        "X_t_unzoomed=np.asarray(X_t_unzoomed).reshape(no_of_test_unzoomed,150,150,3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/x_test_array_unzoomed.csv', X_t_unzoomed)\n"
      ],
      "metadata": {
        "id": "7lurcUZBnlBY"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5309ed-349f-462e-8373-a9a1b3736280",
        "id": "V7ZWcDcGSk1r"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "Y_test_unzoomed=to_categorical(y_test_unzoomed,num_classes=3)\n",
        "print(Y_test_unzoomed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "yY8TyAAVSk1r"
      },
      "outputs": [],
      "source": [
        "savetxt('/content/drive/MyDrive/y_test_unzoomed.csv', Y_test_unzoomed, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XDKLxgWQWSc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "GkyO1rl_WZft"
      },
      "outputs": [],
      "source": [
        "file='/content/drive/MyDrive/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pretrained_model=VGG16(input_shape = (150, 150, 3),\n",
        "                        include_top = False,\n",
        "                        weights =None)\n",
        "\n",
        "pretrained_model.load_weights(file)\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "     layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3de9c7-7c51-48e3-8baa-add547dec589",
        "id": "bzZ4ZKa0WZf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer of vgg : output shape:  (None, 4, 4, 512)\n"
          ]
        }
      ],
      "source": [
        "last_layer = pretrained_model.get_layer('block5_pool')\n",
        "print('last layer of vgg : output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model_vgg16_unzoomed = Model(pretrained_model.input, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "qhS9oUvcWZf0"
      },
      "outputs": [],
      "source": [
        "model_vgg16_unzoomed.compile(optimizer = RMSprop(learning_rate=0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c626c590-7163-4218-c22a-763f90248f16",
        "id": "TIj1BMrRWZf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 5s 105ms/step - loss: 0.2828 - acc: 0.8908 - val_loss: 0.0945 - val_acc: 0.9733\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0579 - acc: 0.9850 - val_loss: 0.0478 - val_acc: 0.9867\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.0261 - acc: 0.9975 - val_loss: 0.0456 - val_acc: 0.9933\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.0154 - acc: 0.9975 - val_loss: 0.0387 - val_acc: 0.9800\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9933\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9900\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 0.9900\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.0050 - acc: 0.9992 - val_loss: 0.0394 - val_acc: 0.9900\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 0.9933\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9933\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9900\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 0.9933\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 8.8207e-04 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9933\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 7.5837e-04 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 0.9933\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 7.8211e-04 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 0.9933\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 4s 104ms/step - loss: 6.3558e-04 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 0.9933\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 5.2032e-04 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 0.9933\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 4.4919e-04 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9933\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 4.3359e-04 - acc: 1.0000 - val_loss: 0.0349 - val_acc: 0.9933\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 4.4892e-04 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 0.9933\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 4.3923e-04 - acc: 1.0000 - val_loss: 0.0371 - val_acc: 0.9933\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 3.2698e-04 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 0.9933\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 3.1183e-04 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 0.9933\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 4s 104ms/step - loss: 2.9276e-04 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9933\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 3.0158e-04 - acc: 1.0000 - val_loss: 0.0420 - val_acc: 0.9933\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 2.5617e-04 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 0.9933\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.9094e-04 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 0.9933\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 2.2679e-04 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 0.9933\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 2.3434e-04 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 0.9933\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 1.9308e-04 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 0.9933\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.9934e-04 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9933\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 2.3179e-04 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 0.9933\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.8418e-04 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 0.9933\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 1.6200e-04 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 0.9933\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.7061e-04 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 0.9933\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.9903e-04 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 0.9933\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.6381e-04 - acc: 1.0000 - val_loss: 0.0381 - val_acc: 0.9933\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.3551e-04 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9933\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 3s 91ms/step - loss: 1.2372e-04 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 0.9933\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 1.5359e-04 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9933\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 1.2385e-04 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9933\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.3967e-04 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 0.9933\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 1.2410e-04 - acc: 1.0000 - val_loss: 0.0349 - val_acc: 0.9933\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.1191e-04 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9933\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.3132e-04 - acc: 1.0000 - val_loss: 0.0354 - val_acc: 0.9933\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 1.1911e-04 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9933\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 1.0996e-04 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9933\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 9.0877e-05 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9933\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 9.2593e-05 - acc: 1.0000 - val_loss: 0.0413 - val_acc: 0.9933\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 1.3316e-04 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 0.9933\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 9.3892e-05 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 0.9933\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 1.0637e-04 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 0.9933\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 9.8938e-05 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 0.9933\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 9.2201e-05 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 0.9933\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 4s 96ms/step - loss: 9.3773e-05 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 0.9933\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 4s 109ms/step - loss: 8.6695e-05 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9933\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 9.4032e-05 - acc: 1.0000 - val_loss: 0.0402 - val_acc: 0.9933\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 8.0082e-05 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9933\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 7.3643e-05 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9933\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 7.4777e-05 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 0.9933\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 7.7984e-05 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9933\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 7.5473e-05 - acc: 1.0000 - val_loss: 0.0453 - val_acc: 0.9933\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 7.4196e-05 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 0.9933\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 7.8467e-05 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 0.9933\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 6.9326e-05 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9933\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 8.2113e-05 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 0.9933\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 7.6218e-05 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9933\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 6.2036e-05 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 0.9933\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 5.8480e-05 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 0.9933\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 6.9289e-05 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9933\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 5.8089e-05 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 0.9933\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 5.8273e-05 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 0.9933\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 5.4231e-05 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9933\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 5.4799e-05 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9933\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 4.7807e-05 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 0.9933\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 5.8748e-05 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9933\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 3s 91ms/step - loss: 5.2031e-05 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 0.9933\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 7.0414e-05 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 0.9933\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 6.3647e-05 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9933\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 5.1412e-05 - acc: 1.0000 - val_loss: 0.0411 - val_acc: 0.9933\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 5.9048e-05 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9933\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 4.4615e-05 - acc: 1.0000 - val_loss: 0.0426 - val_acc: 0.9933\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 5.3499e-05 - acc: 1.0000 - val_loss: 0.0420 - val_acc: 0.9933\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 4.8609e-05 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 0.9933\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 4.9901e-05 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 0.9933\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 4.5321e-05 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 0.9933\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 4.5099e-05 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9933\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 3.4147e-05 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 0.9933\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 4.4805e-05 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 0.9933\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 4.5936e-05 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9933\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 4.1857e-05 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9933\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 4.1044e-05 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9933\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 3.8869e-05 - acc: 1.0000 - val_loss: 0.0424 - val_acc: 0.9933\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 4s 107ms/step - loss: 4.4495e-05 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9933\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 3.8728e-05 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9933\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 3.9875e-05 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 0.9933\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 4s 106ms/step - loss: 4.9286e-05 - acc: 1.0000 - val_loss: 0.0425 - val_acc: 0.9933\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 4.5251e-05 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 0.9933\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 4s 105ms/step - loss: 4.8566e-05 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9933\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 3.7376e-05 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9933\n"
          ]
        }
      ],
      "source": [
        "history = model_vgg16_unzoomed.fit(X_unzoomed,Y_unzoomed,epochs=100,validation_data=(X_t_unzoomed,Y_test_unzoomed))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_acc'], label = 'Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "-Tf8-gWNZHKp",
        "outputId": "51ca9b88-af40-42e7-9e3d-6df139be24d8"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}